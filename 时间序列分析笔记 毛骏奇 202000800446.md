<h1>时间序列分析</h1>

<h2>chapter 1 
Time Series and Their Features</h2>

Time series display a wide variety of features and an appreciation of these is essential for understanding both their properties and their evolution, including calculating future forecasts and, therefore, unknown values of $x_{t}$ at, say, times $T+1, T+2, \ldots, T+h$, where $h$ is referred to as the forecast horizon

The lag-k (sample) autocorrelation is defined as

$$
r_{k}=\frac{\sum_{t=k+1}^{T}\left(x_{t}-\bar{x}\right)\left(x_{t-k}-\bar{x}\right)}{T s^{2}}
$$

where

$$
\bar{x}=T^{-1} \sum_{t=1}^{T} x_{t}
$$

and

$$
s^{2}=T^{-1} \sum_{t=1}^{T}\left(x_{t}-\bar{x}\right)^{2}
$$

are the sample mean and variance of $x_{t}$, respectively.

If the mean level cannot be regarded as constant then a series is said to be nonstationary. Nonstationarity, however, can appear in many guises. 

<h2>Chapter 2 Transforming Time Series</h2>

There are three general classes of transformations for time series-distributional, stationarity inducing, and decompositional-and these may often be combined to produce an appropriate variable to analyze.

DISTRIBUTIONAL TRANSFORMATIONS

Many statistical procedures perform more effectively on data that are normally distributed, or at least are symmetric and not excessively kurtotic (fat-tailed), and where the mean and variance are approximately constant. Observed time series frequently require some form of transformation before they exhibit these distributional properties, for in their "raw" form they are often asymmetric. For example, if a series is only able to take positive (or at least nonnegative) values, then its distribution will usually be skewed to the right, because although there is a natural lower bound to the data, often zero, no upper bound exists and the values are able to "stretch out," possibly to infinity. In this case a simple and popular transformation is to take logarithms, usually to the base $e$ (natural logarithms)

the ratio of cumulative standard deviations, $s_{i}(\mathrm{RPI}) / s_{i}(\log \mathrm{RPI})$, defined using (1.2) and (1.3) as:

$$
s_{i}^{2}(x)=i^{-1} \sum_{t=1}^{i}\left(x_{t}-\bar{x}_{i}\right)^{2} \quad \bar{x}_{i}=i^{-1} \sum_{t=1}^{i} x_{t}
$$

Since this ratio increases monotonically throughout the observation period, the logarithmic transformation clearly helps to stabilize the variance and it will, in fact, do so whenever the standard deviation of a series is proportional to its level.

It is also clear that for attaining approximate normality, the availability of a more general class of transformations would be useful. A class of power transformations that contains the logarithmic as a special case is that proposed by Box and Cox (1964) for positive $x:^{3}$

$$
f^{\mathrm{BC}}\left(x_{t}, \lambda\right)= \begin{cases}\left(x_{t}^{\lambda}-1\right) / \lambda & \lambda \neq 0 \\ \log x_{t} & \lambda=0\end{cases}
$$

Possible alternatives are the signed power transformation proposed by Bickel and Doksum (1981):

$$
f^{\mathrm{SP}}\left(x_{t}, \lambda\right)=\left(\operatorname{sgn}\left(x_{t}\right)\left|x_{t}^{\lambda}\right|-1\right) / \lambda \quad \lambda>0
$$

or the generalized power (GP) transformation suggested by Yeo and Johnson (2000) shown in (2.3)

$$
f^{\mathrm{GP}}\left(x_{t}, \lambda\right)= \begin{cases}\left(\left(x_{t}+1\right)^{\lambda}-1\right) / \lambda & x_{t} \geq 0, \lambda \neq 0 \\ \log \left(x_{t}+1\right) & x_{t} \geq 0, \lambda=0 \\ -\left(\left(-x_{t}+1\right)^{2-\lambda}-1\right) /(2-\lambda) & x_{t}<0, \lambda \neq 2 \\ -\log \left(-x_{t}+1\right) & x_{t}<0, \lambda \neq 2\end{cases}
$$

A further alternative is the inverse hyperbolic sine (IHS) transformation suggested by Burbidge et al. (1988) to deal with extreme values of either sign:

$$
f^{\mathrm{IHS}}\left(x_{t}, \lambda\right)=\frac{\sinh ^{-1}\left(\lambda x_{t}\right)}{\lambda}=\log \frac{\lambda x_{t}+\left(\lambda^{2} x_{t}^{2}+1\right)^{1 / 2}}{\lambda} \quad \lambda>0
$$

First-differencing may, on some occasions, be insufficient to induce stationarity and further differencing may be required. Fig. 2.72.7 shows successive temperature readings on a chemical process, this being Series \mathrm{C}C of Box and Jenkins (1970). The top panel shows observed temperatures. These display a distinctive form of nonstationarity, in which there are almost random switches in trend and changes in level. Although first differencing (shown as the middle panel) mitigates these switches and changes, it by no means eliminates them; second-differences are required to achieve this, as shown in the bottom panel.

The MAs fitted in the previous examples have been interpreted as trends; the long-run, smoothly evolving component of a time series, that is, the "smooth" of a two-component decomposition (recall $\S \mathbf{2 . 1 5}$ ). When a time series is observed at a frequency greater than annual, say monthly or quarterly, a three-component decomposition is often warranted, with the observed series, now denoted $X_{t}$, being decomposed into trend, $T_{t}$, seasonal, $S_{t}$, and irregular, $I_{t}$, components. The decomposition can either be additive:

$$
X_{t}=T_{t}+S_{t}+I_{t}
$$

or multiplicative

$$
X_{t}=T_{t} \times S_{t} \times I_{t}
$$

although the distinction is to some extent artificial, as taking logarithms of (2.12) will produce an additive decomposition for $\log X_{t}$. The seasonal component is a regular, short-term, annual cycle, while the irregular component is what is left over after the trend and seasonal components have been removed; it should with thus be random and hence unpredictable.

The seasonally adjusted series is then defined as either:

$$
X_{t}^{\mathrm{SA}, \mathrm{A}}=X_{t}-S_{t}=T_{t}+I_{t}
$$

or

$$
X_{t}^{\mathrm{SA}, \mathrm{M}}=\frac{X_{t}}{S_{t}}=T_{t} \times I_{t}
$$

depending on which form of decomposition is used.

<h2>Chapter 3 ARMA Models for Stationary Time Series</h2>

STOCHASTIC PROCESSES AND STATIONARITY

the $T$ means:

$$
E\left(x_{1}\right), E\left(x_{2}\right), \ldots, E\left(x_{T}\right)
$$

T variances:

$$
V\left(x_{1}\right), V\left(x_{2}\right), \ldots, V\left(x_{T}\right)
$$

and $T(T-1) / 2$ covariances:

$$
\operatorname{Cov}\left(x_{i}, x_{j}\right), \quad i<j
$$

If the distribution could be assumed to be (multivariate) normal, then this set of expectations would completely characterize the properties of the stochastic process. As has been seen from the examples in Chapter 2, Transforming Time Series, however, such an assumption will not always be appropriate, but if the process is taken to be linear, in the sense that the current value $x_{t}$ is generated by a linear combination of previous values $x_{t-1}, x_{t-2}, \ldots$ of the process itself plus current and past values of any other related processes, then again this set of expectations would capture its major properties.

In either case, however, it will be impossible to infer all the values of the first and second moments from just a single realization of the process, since there are only $T$ observations but $T+T(T+1) / 2$ unknown parameters. Consequently, further simplifying assumptions must be made to reduce the number of unknown parameters to more manageable proportions.

 A stochastic process is said to be strictly stationary if its properties are unaffected by a change of time origin, that is, the joint probability distribution at any set of times $t_{1}, t_{2}, \ldots, t_{m}$ must be the same as the joint probability distribution at $t_{1+k}, t_{2+k}, \ldots, t_{m+k}$, where $k$ is an arbitrary shift in time. For $m=1$, strict stationarity implies that the marginal probability distributions at $t_{1}, t_{2}, \ldots$ do not depend on time, which in turn implies that as long as $E\left|x_{t}^{2}\right|<\infty$ (which is part of a finite second moment assumption) both the mean and variance of $x_{t}$ must be constant, so that:

$$
E\left(x_{1}\right)=E\left(x_{2}\right)=\cdots=E\left(x_{T}\right)=\mu
$$

and

$$
V\left(x_{1}\right)=V\left(x_{2}\right)=\cdots=V\left(x_{T}\right)=\sigma_{x}^{2}
$$

If $m=2$, strict stationarity implies that all bivariate distributions do not depend on time, so that covariances are functions of the time-shift (or lag) $k$ only, hence implying that for all $k$,

$$
\operatorname{Cov}\left(x_{1}, x_{1+k}\right)=\operatorname{Cov}\left(x_{2}, x_{2+k}\right)=\cdots=\operatorname{Cov}\left(x_{T-k}, x_{T}\right)=\operatorname{Cov}\left(x_{t}, x_{t-k}\right)
$$

This leads to the definition of the lag-k autocovariance as:

$$
\gamma_{k}=\operatorname{Cov}\left(x_{t}, x_{t-k}\right)=E\left(\left(x_{t}-\mu\right)\left(x_{t-k}-\mu\right)\right)
$$

so that

$$
\gamma_{0}=E\left(x_{t}-\mu\right)^{2}=V\left(x_{t}\right)=\sigma_{x}^{2}
$$

and the lag- $k$ autocorrelation may then be defined as

$$
\rho_{k}=\frac{\operatorname{Cov}\left(x_{t}, x_{t-k}\right)}{\left(V\left(x_{t}\right) V\left(x_{t-k}\right)\right)^{1 / 2}}=\frac{\gamma_{k}}{\gamma_{0}}=\frac{\gamma_{k}}{\sigma_{x}^{2}}
$$

The set of assumptions that the mean and variance of $x_{t}$ are both constant and the autocovariances and autocorrelations depend only on the lag $k$ is known as weak or covariance stationarity.

WOLD'S DECOMPOSITION AND AUTOCORRELATION

A fundamental theorem in time series analysis, known as Wold's decomposition, states that every weakly stationary, purely nondeterministic, stochastic process $x_{t}-\mu$ can be written as a linear combination (or linear filter) of a sequence of uncorrelated random variables. ${ }^{2}$ "Purely nondeterministic" means that any deterministic components have been subtracted from $x_{t}-\mu$. Such components are those that can be perfectly predicted from past values of themselves and examples commonly found are a (constant) mean, as is implied by writing the process as $x_{t}-\mu$, periodic sequences (e.g., sine and cosine functions), and polynomial or exponential sequences in $t$.

This linear filter representation is given by:

$$
x_{t}-\mu=a_{t}+\psi_{1} a_{t-1}+\psi_{2} a_{t-2}+\cdots=\sum_{j=0}^{\infty} \psi_{j} a_{t-j} \quad \psi_{0}=1
$$

The $a_{t}, t=0, \pm 1, \pm 2, \ldots$ are a sequence of uncorrelated random variables, often known as innovations, drawn from a fixed distribution with:

$$
E\left(a_{t}\right)=0 \quad V\left(a_{t}\right)=E\left(a_{t}^{2}\right)=\sigma^{2}<\infty
$$

and

$$
\operatorname{Cov}\left(a_{t}, a_{t-k}\right)=E\left(a_{t} a_{t-k}\right)=0, \text { for all } k \neq 0
$$

Such a sequence is known as a white noise process, and occasionally the innovations will be denoted as $a_{t} \sim \operatorname{WN}\left(0, \sigma^{2}\right) .^{3}$ The coefficients (possibly infinite in number) in the linear filter (3.2) are known as $\psi$-weights.

It is easy to show that the model (3.2) leads to autocorrelation in $x_{t}$. From this equation it follows that:

$$
E\left(x_{t}\right)=\mu
$$

and

$$
\begin{aligned}
\gamma_{0} &=V\left(x_{t}\right)=E\left(x_{t}-\mu\right)^{2} \\
&=E\left(a_{t}+\psi_{1} a_{t-1}+\psi_{2} a_{t-2}+\cdots\right)^{2} \\
&=E\left(a_{t}^{2}\right)+\psi_{1}^{2} E\left(a_{t-1}^{2}\right)+\psi_{2}^{2} E\left(a_{t-2}^{2}\right)+\cdots \\
&=\sigma^{2}+\psi_{1}^{2} \sigma^{2}+\psi_{2}^{2} \sigma^{2}+\cdots \\
&=\sigma^{2} \sum_{j=0}^{\infty} \psi_{j}^{2}
\end{aligned}
$$

by using the white noise result that $E\left(a_{t-i} a_{t-j}\right)=0$ for $i \neq j$. Now:

$$
\begin{aligned}
\gamma_{k} &=E\left(x_{t}-\mu\right)\left(x_{t-k}-\mu\right) \\
&=E\left(a_{t}+\psi_{1} a_{t-1}+\cdots+\psi_{k} a_{t-k}+\cdots\right)\left(a_{t-k}+\psi_{1} a_{t-k-1}+\cdots\right) \\
&=\sigma^{2}\left(1 \cdot \psi_{k}+\psi_{1} \psi_{k+1}+\psi_{2} \psi_{k+2}+\cdots\right) \\
&=\sigma^{2} \sum_{j=0}^{\infty} \psi_{j} \psi_{j+k}
\end{aligned}
$$

and this implies

$$
\rho_{k}=\frac{\sum_{j=0}^{\infty} \psi_{j} \psi_{j+k}}{\sum_{j=0}^{\infty} \psi_{j}^{2}}
$$

If the number of $\psi$-weights in (3.2) is infinite, the weights must be assumed to be absolutely summable, so that $\sum_{j=0}^{\infty}\left|\psi_{j}\right|<\infty$, in which case the linear filter representation is said to converge. This condition can be shown to be equivalent to assuming that $x_{t}$ is stationary, and guarantees that all moments exist and are independent of time, in particular that the variance of $x_{t}, \gamma_{0}$, is finite. 

FIRST-ORDER AUTOREGRESSIVE PROCESSES

Although Eq. (3.2) may appear complicated, many realistic models result from specific choices for the $\psi$-weights. Taking $\mu=0$ without loss of generality, choosing $\psi_{j}=\phi^{j}$ allows (3.2) to be written as:

$$
\begin{aligned}
x_{t} &=a_{t}+\phi a_{t-1}+\phi^{2} a_{t-2}+\cdots \\
&=a_{t}+\phi\left(a_{t-1}+\phi a_{t-2}+\cdots\right) \\
&=\phi x_{t-1}+a_{t}
\end{aligned}
$$

or

$$
x_{t}-\phi x_{t-1}=a_{t}
$$

This is known as a first-order autoregressive process, often given the acronym $\operatorname{AR}(1) .^{4}$

The lag operator $B$ introduced in $\S \mathbf{2 . 1 0}$ allows (possibly infinite) lag expressions to be written in a concise way. For example, by using this operator the $\operatorname{AR}(1)$ process can be written as:

$$
(1-\phi B) x_{t}=a_{t}
$$

so that

$$
\begin{aligned}
x_{t} &=(1-\phi B)^{-1} a_{t}=\left(1+\phi B+\phi^{2} B^{2}+\cdots\right) a_{t} \\
&=a_{t}+\phi a_{t-1}+\phi^{2} a_{t-2}+\cdots
\end{aligned}
$$

This linear filter representation will converge if $|\phi|<1$, which is, therefore, the stationarity condition.

The ACF of an AR(1) process may now be deduced. Multiplying both sides of (3.3) by $x_{t-k}, k>0$, and taking expectations yields:

$$
\gamma_{k}-\phi \gamma_{k-1}=E\left(a_{t} x_{t-k}\right) .
$$

From (3.4), $a_{t} x_{t-k}=\sum_{i=0}^{\infty} \phi^{i} a_{t} a_{t-k-i}$. As $a_{t}$ is white noise, any term in $a_{t} a_{t-k-i}$ has zero expectation if $k+i>0$. Thus (3.5) simplifies to:

$$
\gamma_{k}=\phi \gamma_{k-1} \text { for all } k>0
$$

and, consequently, $\gamma_{k}=\phi^{k} \gamma_{0}$. An AR(1) process, therefore, has an ACF given by $\rho_{k}=\phi^{k}$. Thus, if $\phi>0$ the ACF decays exponentially to zero, while if $\phi<0$ the ACF decays in an oscillatory pattern, both decays being slow if $\phi$ is close to the nonstationary boundaries of $+1$ and $-1$.

FIRST-ORDER MOVING AVERAGE PROCESSES

3.12 Now consider the model obtained by choosing $\psi_{1}=-\theta$ and $\psi_{j}=0$, $j \geq 2$, in (3.2):

$$
x_{t}=a_{t}-\theta a_{t-1}
$$

or

$$
x_{t}=(1-\theta B) a_{t}
$$

This is known as the first-order moving average (MA(1)) process and it follows immediately that: ${ }^{5}$

$$
\gamma_{0}=\sigma^{2}\left(1+\theta^{2}\right) \quad \gamma_{1}=-\sigma^{2} \theta \quad \gamma_{k}=0 \text { for } k>1
$$

and, hence, its ACF is described by 

$$
\rho_{1}=-\frac{\theta}{1+\theta^{2}} \quad \rho_{k}=0 \text { for } k>1
$$

Thus, although observations one period apart are correlated, observations more than one period apart are not, so that the memory of the process is just one period: this "jump" to zero autocorrelation at $k=2$ may be contrasted with the smooth, exponential decay of the ACF of an $\mathrm{AR}(1)$ process.

3.13 The expression for $\rho_{1}$ can be written as the quadratic equation $\rho_{1} \theta^{2}+\theta+\rho_{1}=0$. Since $\theta$ must be real, it follows that $\left|\rho_{1}\right|<0.5$. $^{6}$ However, both $\theta$ and $1 / \theta$ will satisfy this equation, and thus, two $\mathrm{MA}(1)$ processes can always be found that correspond to the same ACF.

3.14 Since any MA model consists of a finite number of $\psi$-weights, all MA models are stationary. To obtain a converging autoregressive representation, however, the restriction $\theta<1$ must be imposed. This restriction is known as the invertibility condition and implies that the process can be written in terms of an infinite autoregressive representation:

$$
x_{t}=\pi_{1} x_{t-1}+\pi_{2} x_{t-2}+\cdots+a_{t}
$$

where the $\pi$-weights converge: $\sum_{j=1}^{\infty}\left|\pi_{j}\right|<\infty$. In fact, the $\operatorname{MA}(1)$ model can be written as:

$$
(1-\theta B)^{-1} x_{t}=a_{t}
$$

and expanding $(1-\theta B)^{-1}$ yields

$$
\left(1+\theta B+\theta^{2} B^{2}+\cdots\right) x_{t}=a_{t} .
$$

The weights $\pi_{j}=\theta^{i}$ will converge if $|\theta|<1$; in other words, if the model is invertible. This implies the reasonable assumption that the effect of past observations decreases with age.

ARMA MODEL BUILDING AND ESTIMATION

 An essential first step in fitting ARMA models to observed time series is to obtain estimates of the generally unknown parameters $\mu, \sigma_{x}^{2}$, and the $\rho_{k}$. With the stationarity and (implicit) ergodicity assumptions, $\mu$ and $\sigma_{x}^{2}$ can be estimated by the sample mean and sample variance, respectively, of the realization $x_{1}, x_{2}, \ldots, x_{T}$, that is, by Eqs. (1.2) and (1.3). An estimate of $\rho_{k}$ is then provided by the lag $k$ sample autocorrelation given by Eq. (1.1), which, because of its importance, is reproduced here:

$$
r_{k}=\frac{\sum_{t=k+1}^{T}\left(x_{t}-\bar{x}\right)\left(x_{t-k}-\bar{x}\right)}{T s^{2}} \quad k=1,2, \ldots
$$

Recall from $\S \mathbf{1 . 2}$ that the set of $r_{k} \mathrm{~s}$ defines the sample ACF (SACF), which is sometimes referred to as the correlogram.

3.30 Consider a time series generated as independent observations drawn from a fixed distribution with finite variance (i.e., $\rho_{k}=0$ for all $k \neq 0$ ). Such a series is said to be independent and identically distributed or i.i.d. For such a series the variance of $r_{k}$ is approximately given by $T^{-1}$. If $T$ is large as well, $\sqrt{T} r_{k}$ will be approximately standard normal, so that $r_{k} \stackrel{a}{\sim} N\left(0, T^{-1}\right)$, implying that an absolute value of $r_{k}$ in excess of $2 / \sqrt{T}$ may be regarded as "significantly" different from zero at the $5 \%$ significance level. More generally, if $\rho_{k}=0$ for $k>q$, the variance of $r_{k}$, for $k>q$, is:

$$
V\left(r_{k}\right)=T^{-1}\left(1+2 \rho_{1}^{2}+\cdots+2 \rho_{q}^{2}\right) .
$$

Thus, by successively increasing the value of $q$ and replacing the $\rho_{k}$ s by their sample estimates, the variances of the sequence $r_{1}, r_{2}, \ldots, r_{k}$ can be estimated as $T^{-1}, T^{-1}\left(1+2 r_{1}^{2}\right), \ldots, T^{-1}\left(1+2 r_{1}^{2}+\cdots+2 r_{k-1}^{2}\right)$, and, of course, these will be larger for $k>1$ than those calculated using the simple formula $T^{-1}$. Taking the square root of $V\left(r_{k}\right)$ gives the standard error to be attached to $r_{k}$ and these are often referred to as Bartlett standard errors, as (3.12) was derived in Bartlett (1946).

3.31 The sample partial ACF (SPACF) is usually calculated by fitting autoregressive models of increasing order; the estimate of the last coefficient in each model is the sample partial autocorrelation, $\hat{\phi}_{k k} \cdot{ }^{9}$ If the data follow an $\operatorname{AR}(p)$ process then for lags greater than $p$ the variance of $\hat{\phi}_{k k}$ is approximately $T^{-1}$, so that $\hat{\phi}_{k k} \stackrel{a}{\sim} N\left(0, T^{-1}\right)$

3.32 Given the $r_{k}$ and $\hat{\phi}_{k k}$, the approach to ARMA model building proposed by George Box and Gwilym Jenkins-the Box and Jenkins (1970) approach-may be followed. This is a three-stage procedure, the first of which, known as the identification stage, is essentially to match the behavior of the SACF and SPACF of a time series with that of various theoretical ACFs and PACFs. This may be done by assessing individual sample autocorrelations and partial autocorrelations for significance by comparing them to their accompanying standard errors computed according to the formulae of $\S \S$ 3.30-3.31. Additionally, a "portmanteau" statistic based on the complete set of $r_{k} \mathrm{~s}$ may be constructed. On the hypothesis that $x_{t} \sim \mathrm{WN}\left(\mu, \sigma^{2}\right)$, then Ljung and Box (1978) show that:

$$
Q(k)=T(T+2) \sum_{i=1}^{k}(T-i)^{-1} r_{i}^{2} \stackrel{a}{\sim} \chi^{2}(k)
$$

and this statistic may be used to assess whether an observed series departs significantly from white noise (but see $\S \mathbf{1 1 . 5}$ for more specific assumptions concerning $\left.x_{t}\right)$.

3.33 Having picked the best match (or set of matches), the second stage is to estimate the unknown model parameters (the $\phi_{i} \mathrm{~s}, \theta_{i} \mathrm{~s}, \mu$, and $\sigma^{2}$ ). If the model is a pure autoregression, then ordinary least squares (OLS) is an efficient and perfectly acceptable estimation method as it produces the conditional $M L$ estimates of the parameters; here "conditional" means that the likelihood function is maximized conditional on regarding $x_{1}, x_{2}, \ldots, x_{p}$ as deterministic and, hence, given by their observed values rather than as being taken as random variables drawn from the underlying distribution. If the sample size $T$ is large, then these first $p$ observations make a negligible contribution to the total likelihood and conditional ML will have the same largesample distribution for the estimates $\hat{\phi}_{1}, \hat{\phi}_{2}, \ldots, \hat{\phi}_{p}, \mu, \hat{\sigma}^{2}$ as exact ML.

If there is an MA component, then a simple approach is to condition on the assumption that $a_{p-q+1}, a_{p-q+2}, \ldots, a_{p}$ all take their expected value of zero. This is known as conditional least squares (CLS) and, again, is equivalent to exact ML in large samples; the estimates of the additional MA parameters being denoted $\hat{\theta}_{1}, \hat{\theta}_{2}, \ldots, \hat{\theta}_{q}$. Other approaches to computing exact ML estimates in small samples are available if necessary.

3.34 Finally, the third stage, diagnostic checking, is to examine the residuals:

$$
\hat{a}_{t}=x_{t}-\hat{\phi}_{1} x_{t-1}-\cdots-\hat{\phi}_{p} x_{t-p}-\hat{\theta}_{1} \hat{a}_{t-1}-\cdots-\hat{\theta}_{q} \hat{a}_{t-q}
$$

from the fitted model(s) for any possible misspecifications. Misspecifications typically take the form of autocorrelated residuals, so that the SACF of the $\hat{a}_{t}$ will contain one or more significant values. Significance can be assessed by comparing individual residual autocorrelations, say $\hat{r}_{k}$, with their standard error, which will be $T^{-1 / 2}$ under the null that the residuals are not misspecified and, hence, are white noise. Alternatively, the portmanteau statistic (3.13) may be computed, although the degrees of freedom for $Q$ must now be decreased to $k-p-q$ if an $\operatorname{ARMA}(p, q)$ has been fitted. A further check on the adequacy of the fitted model is to overfit, say by estimating an $\operatorname{ARMA}(p+1, q)$ or an $\operatorname{ARMA}(p, q+1)$ process and checking whether the additional fitted parameter is significant or not. If any deficiencies in the model(s) are encountered, then further rounds of model building must be undertaken until a well-specified model with no obvious deficiencies is obtained. ${ }^{10}$

3.35 This three-stage approach, developed in the 1960s when computing power was extremely limited and software unavailable (indeed, Box and Jenkins had to write all their programs from scratch), may strike modern readers as unnecessarily labor intensive, although it will become apparent that it does have some important advantages in that it enables analysts to obtain a detailed "feel" of the data. Consequently, an alternative approach that harnesses modern computer power and software availability is to select a set of models based on prior considerations of maximum settings of $p$ and $q$, estimate each possible model, and select that which minimizes a chosen selection criterion based on goodness of fit considerations.

3.36 There are a variety of selection criteria that may be used to choose an appropriate model, of which perhaps the most popular is Akaike's (1974) Information Criteria (AIC), defined as:

$$
\operatorname{AIC}(p, q)=\log \hat{\sigma}^{2}+2(p+q) T^{-1}
$$

although a criterion that has better theoretical properties is the BIC of Schwarz (1978)

$$
B I C(p, q)=\log \hat{\sigma}^{2}+(p+q) T^{-1} \log T .
$$

The criteria are used in the following way. Upper bounds, say $p_{\max }$ and $q_{\max }$, are set for the orders of $\phi(B)$ and $\theta(B)$, with $\bar{p}=\left\{0,1, \ldots, p_{\max }\right\}$ and $\bar{q}=\left\{0,1, \ldots, q_{\max }\right\}$, orders $p_{1}$ and $q_{1}$ are selected such that, for example;

$$
\operatorname{AIC}\left(p_{1}, q_{1}\right)=\min \operatorname{AIC}(p, q) \quad p \in \bar{p}, \quad q \in \bar{q}
$$

with parallel strategies obviously being employed in conjunction with BIC. One possible difficulty with the application of this strategy is that no specific guidelines on how to determine $\bar{p}$ and $\bar{q}$ seem to be available, although they are tacitly assumed to be sufficiently large for the range of models to contain the "true" model, which may be denoted as having orders $\left(p_{0}, q_{0}\right)$ : these, of course, will not necessarily be the same as $\left(p_{1}, q_{1}\right)$, the orders chosen by the criterion under consideration.

Given these alternative criteria, are there reasons for preferring one to the other? If the true orders $\left(p_{0}, q_{0}\right)$ are contained in the set $(p, q), p \in \bar{p}, q \in \bar{q}$, then for all criteria, $p_{1} \geq p_{0}$ and $q_{1} \geq q_{0}$, almost surely, as $T \rightarrow \infty$. However, BIC is strongly consistent in the sense that it will determine the true model asymptotically, whereas for AIC an over-parameterized model will emerge no matter how long the available realization. Of course, such properties are not necessarily guaranteed in finite samples, so that both criteria are often used together. ${ }^{1}$

These model building procedures will not be discussed in any further detail; rather, they will be illustrated by way of a sequence of examples designed to bring out many of the features encountered in practice when using these procedures.

<h2>Chapter 4 ARIMA Models for Nonstationary Time Series</h2>

NONSTATIONARITY

4.1 The autoregressive-moving average (ARMA) class of models relies on the assumption that the underlying process is weakly stationary, which restricts the mean and variance to be constant and requires the autocovariances to depend only on the time lag. As we have seen, however, many time series are certainly not stationary, for they tend to exhibit timechanging means and/or variances.

4.2 To deal with such nonstationarity, we begin by characterizing a time series as the sum of a nonconstant mean level plus a random error component:

$$
x_{t}=\mu_{t}+\varepsilon_{t}
$$

The nonconstant mean level $\mu_{t}$ in (4.1) can be modeled in a variety of ways. One potentially realistic possibility is that the mean evolves as a (nonstochastic) polynomial of order $d$ in time, with the error $\varepsilon_{t}$ assumed to be a stochastic, stationary, but possibly autocorrelated, zero mean process. This, in fact, is always possible given Cramer's (1961) extension of Wold's decomposition theorem to nonstationary processes. Thus, we may have:

$$
x_{t}=\mu_{t}+\varepsilon_{t}=\sum_{j=0}^{d} \beta_{j} t^{j}+\psi(B) a_{t}
$$

Since:

$$
E\left(\varepsilon_{t}\right)=\psi(B) E\left(a_{t}\right)=0,
$$

we have

$$
E\left(x_{t}\right)=E\left(\mu_{t}\right)=\sum_{j=0}^{d} \beta_{j} t^{j}
$$

and, as the $\beta_{j}$ coefficients remain constant through time, such a trend in the mean is said to be deterministic.

ARIMA PROCESSES

4.6 As we can see from (4.6), the solution to (4.5) is explosive if $\phi>1$ but stationary if $\phi<1$. The case $\phi=1$ produces a process that is neatly balanced between the two. If $x_{t}$ is generated by the model:

$$
x_{t}=x_{t-1}+a_{t}
$$

then $x_{t}$ is said to follow a random walk. ${ }^{2}$ If we allow a constant, $\theta_{0}$, to be included, so that:

$$
x_{t}=x_{t-1}+\theta_{0}+a_{t}
$$

then $x_{t}$ will follow a random walk with drift. If the process starts at $t=0$, then:

$$
x_{t}=x_{0}+t \theta_{0}+\sum_{i=0}^{t} a_{t-i},
$$

so that

$$
\mu_{t}=E\left(x_{t}\right)=x_{0}+t \theta_{0}
$$



$$
\gamma_{0, t}=V\left(x_{t}\right)=t \sigma^{2}
$$

and

$$
\gamma_{k, t}=\operatorname{Cov}\left(x_{t}, x_{t-k}\right)=(t-k) \sigma^{2} \quad k \geq 0
$$

are all functions of $t$ and, hence, are time-varying.

ARIMA MODELING

4.14 Once the order of differencing $d$ has been established, then since $w_{t}=\nabla^{d} x_{t}$ is, by definition, stationary, the ARMA model building techniques discussed in $\S \S 3.29-3.35$ may be applied to the suitably differenced series. Establishing the correct order of differencing is by no means straightforward however, and is discussed in detail in $\S \S 5.4-5.7$. We content ourselves here with a sequence of examples illustrating the modeling of ARIMA processes when $d$ has already been chosen; the suitability of these choices will be examined through examples in Chapter 5, ARIMA Models for Nonstationary Time Series.

<h2>Chapter 5 Unit Roots, Difference and Trend Stationarity, and Fractional Differencing</h2>

DETERMINING THE ORDER OF INTEGRATION OF A TIME SERIES

5.1 As we have shown in $\S \$ 4.5-\mathbf{4 . 1 3}$, the order of integration, $d$, is a crucial determinant of the properties exhibited by a time series. If we restrict ourselves to the most common values of zero and one for $d$, so that $x_{t}$ is either $I(0)$ or $I(1)$, then it is useful to bring together the properties of these two processes.

If $x_{t}$ is $I(0)$, which we will sometimes denote $x_{t} \sim I(0)$ even though such a notation has been used previously to denote the distributional characteristics of a series, then, if we assume for convenience that $x_{t}$ has zero mean;

1. the variance of $x_{t}$ is finite and does not depend on $t$;

2. the innovation $a_{t}$ has only a temporary effect on the value of $x_{t}$;

3. the expected length of time between crossings of $x=0$ is finite, so that $x_{t}$ fluctuates around its mean of zero;

4. the autocorrelations, $\rho_{k}$, decrease steadily in magnitude for large enough $k$, so that their sum is finite. If, on the other hand, $x_{t} \sim I(1)$ with $x_{0}=0$, then;
   


5. the variance of $x_{t}$ goes to infinity as $t$ goes to infinity;

6. an innovation $a_{t}$ has a permanent effect on the value of $x_{t}$ because $x_{t}$ is the sum of all previous innovations: recall from $\$ 4.10$ that $x_{t}=\nabla^{-1} a_{t}=S a_{t}=\sum_{i=0}^{t-1} a_{t-i}$;

7. the expected time between crossings of $x=0$ is infinite;

8. the autocorrelations $\rho_{k} \rightarrow 1$ for all $k$ as $t$ goes to infinity.

TESTING FOR A UNIT ROOT

5.4 Given the importance of choosing the correct order of differencing, we should have available a formal testing procedure to determine $d$. To introduce the issues involved in developing such a procedure, we begin by considering the simplest case, that of the zero mean AR(1) process:

$$
x_{t}=\phi x_{t-1}+a_{t} \quad t=1,2, \ldots, T
$$

where $a_{t} \sim \operatorname{WN}\left(0, \sigma^{2}\right)$ and $x_{0}=0$. The OLS estimator of $\phi$ is given by

$$
\hat{\phi}_{T}=\frac{\sum_{t=1}^{T} x_{t-1} x_{t}}{\sum_{t=1}^{T} x_{t}^{2}}
$$

As we have seen, $x_{t}$ will be $I(0)$ if $|\phi|<1$, but will be $I(1)$ if $\phi=1$, so that testing this null hypothesis, that of a "unit root," becomes a method of determining the correct order of differencing/integration. Given the estimate $\hat{\phi}_{T}$, a conventional way of testing the null hypothesis would be to construct the $t$-statistic

$$
t_{\phi}=\frac{\hat{\phi}_{T}-1}{\hat{\sigma}_{\hat{\phi}_{T}}}=\frac{\hat{\phi}_{T}-1}{\left(s_{T}^{2} / \sum_{t=1}^{T} x_{t-1}^{2}\right)^{1 / 2}}
$$

where

$$
\hat{\sigma}_{\phi_{T}}=\left(\frac{s_{T}^{2}}{\sum_{t=1}^{T} x_{t-1}^{2}}\right)^{1 / 2}
$$

is the usual OLS standard error for $\hat{\phi}_{T}$ and $s_{T}^{2}$ is the OLS estimator of $\sigma^{2}$ :

$$
s_{T}^{2}=\frac{\sum_{t=1}^{T}\left(x_{t}-\hat{\phi}_{T} x_{t-1}\right)^{2}}{T-1}
$$

TREND VERSUS DIFFERENCE STATIONARITY

$5.9$ In the unit root testing strategy outlined previously, the implicit null hypothesis is that the series is generated as a driftless random walk with, possibly, autocorrelated innovations. In popular terminology introduced by Nelson and Plosser (1982), $x_{t}$ is said to be difference stationary (DS),

$$
\nabla x_{t}=\varepsilon_{t}
$$

where $\varepsilon_{t}=\theta(B) a_{t}$, while the alternative is that $x_{t}$ is stationary in levels. While the null of a driftless random walk is appropriate for many time series, others often do contain a drift, so that the relevant null becomes

$$
\nabla x_{t}=\theta+\varepsilon_{t}
$$

In this case, a plausible alternative is that $x_{t}$ is generated by a linear trend buried in stationary noise (see $\S \mathbf{4 . 1 3}$ ), now termed trend stationarity (TS):

$$
x_{t}=\beta_{0}+\beta_{1} t+\varepsilon_{t}
$$

Unfortunately, the $\tau_{\mu}$ statistic obtained from (5.5) is incapable of distinguishing a stationary process around a linear trend [model (5.8)] from a process 

Stationary?

Fig. $5.4$ plots, on a logarithmic scale, monthly observations from 1952 to 2017 on the FTSE All Share stock market index; the broadest based of the London Stock Exchange's price indices. The index has a pronounced tendency to drift upwards, albeit with some major "wanderings" about trend, most notably over the past decade and a half of the sample period, roughly since the beginning of the 2000 s. We may, thus, investigate whether a DS representation of the logarithms of the index is appropriate or whether a TS model would be preferable.

Setting the lag augmentation at $k=1$, as suggested by the $\mathrm{BIC}$, leads to the trend-included ADF regression:

$$
\nabla x_{t}=\underset{(0.020)}{0.049}+\underset{(0.000033)}{0.000064} t-\underset{(0.005)}{0.011} x_{t-1}+\underset{(0.035)}{0.118} \nabla x_{t-1}+\hat{a}_{t}
$$

This yields the test statistic $\tau_{\tau}=-2.13$. Since the $10 \%$ critical value is $-3.13$, there is no evidence against the hypothesis that the logarithm of the index is DS. If the logarithms of the index had been TS, this would have implied that they evolved as autocorrelated deviations about a linear trend, again providing traders with a one-way bet whenever the index got too far away from this trend. Even a cursory examination of Fig. $5.4$ shows that such a representation is clearly false. 

TESTING FOR MORE THAN ONE UNIT ROOT

5.11 This development of unit root tests has been predicated on the assumption that $x_{t}$ contains at most one unit root, so that it is either $I(0)$ or $I(1)$. If the null hypothesis of a unit root is not rejected, then it may be necessary to test whether the series contains a second unit root-in other words whether $x_{t}$ is $I(2)$ and, thus, needs differencing twice to induce stationarity.

OTHER APPROACHES TO TESTING FOR A UNIT ROOT

5.12 An alternative unit root test to the ADF for dealing with autocorrelation in $a_{t}$, which also allows for heterogeneity of variance, has been proposed by Phillips and Perron (1988). Rather than including extra lags of $\nabla x_{t}$ to ensure that the errors of $(5.4)$ are indeed white noise, the idea here is to estimate an "unaugmented" model-(5.3), say-and to modify the test statistics so that the effects of any autocorrelation are accounted for. This will enable the same DF limiting distributions and, hence, critical values to be used.

Under a specific set of conditions placed upon $a_{t}$, known as weak dependency, which are described in detail by Phillips (1987), the $\tau_{\mu}$ statistic obtained from the estimation of $(5.3)$ is modified to

$$
Z\left(\tau_{\mu}\right)=\tau_{\mu}\left(\hat{\sigma}_{0} / \hat{\sigma}_{\ell}\right)-\frac{1}{2}\left(\hat{\sigma}_{\ell}^{2}-\hat{\sigma}_{0}^{2}\right) / \Sigma_{\ell}
$$

in which

$$
\begin{aligned}
\hat{\sigma}_{0}^{2} &=T^{-1} \sum_{t=1}^{T} \hat{a}_{t}^{2} \\
\hat{\sigma}_{\ell}^{2} &=\hat{\sigma}_{0}^{2}+2 T^{-1} \sum_{j=1}^{\ell} w_{j}(\ell)\left(\sum_{t=j+1}^{T} \hat{a}_{t} \hat{a}_{t-j}\right) \\
\sum_{\ell}^{2} &=T^{-2} \hat{\sigma}_{\ell}^{2} \sum_{t=2}^{T}\left(x_{t-1}-\bar{x}_{-1}\right)^{2} \bar{x}_{-1}=(T-1)^{-1} \sum_{t=1}^{T-1} x_{t}
\end{aligned}
$$

$\hat{\sigma}_{\ell}^{2}$ is a consistent estimator of the long-run variance and employs a window or kernel function $w_{j}(\ell)$ to weight the sample autocovariances appearing in the formula. This ensures that the estimator remains positive, with $\ell$ acting as a truncation lag, much like $k$ in the ADF regression. A range of kernel functions are available, such as the "triangular" set of lag weights $w_{j}(\ell)=\ell-j /(\ell+1) . Z\left(\tau_{\mu}\right)$ is often referred to as the Phillips-Perron (PP) non-parametric unit root test.

$Z\left(\tau_{\mu}\right)$ has the same limiting distribution as $\tau_{\mu}$, so that the latter's critical values may again be used. If $x_{t}$ has zero mean, the adjusted statistic, $Z(\tau)$, is as in (5.10) with $\bar{x}_{-1}$ removed and has the same limiting distribution as $\tau$. If a time trend is included then a further adjustment is required to enable the statistic, now denoted $Z\left(\tau_{\tau}\right)$, to have the limiting $\tau_{\tau}$ distribution (Mills and Markellos, 2008, page 87 , for example, provide details).

ESTIMATING TRENDS ROBUSTLY

5.17 Consider again the linear trend model (5.8): $x_{t}=\beta_{0}+\beta_{1} t+\varepsilon_{t}$. As we have seen, correct specification of the trend is crucially important for unit root and stationarity testing. As was pointed out in $\S \mathbf{5 . 9}$, incorrectly excluding a linear trend renders the $\tau_{\mu}$ statistic inconsistent, while it is also the case that unnecessarily including a trend vastly reduces the power of the $\tau_{\tau}$ test, with similar problems affecting the KPSS stationarity statistics $\eta_{\mu}$ and $\eta_{\tau}$.

Often, however, the trend parameter $\beta_{1}$ is of direct interest, especially when ascertaining whether a trend is present $\left(\beta_{1} \neq 0\right)$ or not $\left(\beta_{1}=0\right)$. This may be assessed by either constructing a direct test of the no trend hypothesis $\beta_{1}=0$ or by forming a confidence interval for $\beta_{1}$. Such tests rely on whether $\varepsilon_{t}$, and hence, $x_{t}$, is either $I(0)$ or $I(1)$, but this can only be established after a unit root or stationarity test has been performed-yet the properties of these latter tests rely, in turn, on whether a trend has been correctly included or not! This circularity of reasoning has prompted the development of trend function testing procedures that are robust, in the sense that, at least asymptotically, inference on the trend function is unaffected as to whether $\varepsilon_{t}$ is $I(0)$ or $I(1)$.

FRACTIONAL DIFFERENCING AND LONG MEMORY

5.23 Our analysis has so far only considered cases where the order of differencing, $d$, is either zero, one, or possibly two. Concentrating on the first two cases, if $x_{t} \sim I(1)$ then its ACF declines linearly, whereas if $x_{t} \sim I(0)$ its ACF exhibits an exponential decline, so that observations far apart may be assumed to be independent, or at least nearly so. Many empirically observed time series, however, although appearing to satisfy the assumption of stationarity (perhaps after differencing), nevertheless seem to exhibit some dependence between distant observations that, although small, is by no means negligible. This may be termed long range persistence or dependence, although the term long memory is now popular. ${ }^{6}$

Such series have particularly been found in hydrology, where the longrange persistence of river flows is known as the Hurst effect (see, e.g., Mandelbrot and Wallis, 1969; Hosking, 1984), but many financial time series also exhibit similar characteristics of extremely long persistence. This may be characterized as a tendency for large values to be followed by further large values of the same sign, in such a way that the observations appear to go through a succession of "cycles," including long cycles whose length is comparable to the total sample size.

TESTING FOR FRACTIONAL DIFFERENCING

$5.28$ The "classic" approach to detecting the presence of long memory in a time series is to use the range over standard deviation or rescaled range $(R / S)$ statistic. This was originally developed by Hurst (1951) when studying river discharges and a revised form was later proposed in an economic context by Mandelbrot (1972). It is defined as the range of partial sums of deviations of a time series from its mean, rescaled by its standard deviation, i.e.,

$$
R_{0}=\hat{\sigma}_{0}^{-1}\left[\max _{1 \leq i \leq T} \sum_{t=1}^{i}\left(x_{t}-\bar{x}\right)-\min _{1 \leq i \leq T} \sum_{t=1}^{i}\left(x_{t}-\bar{x}\right)\right] \quad \hat{\sigma}_{0}^{2}=T^{-1} \sum_{t=1}^{T}\left(x_{t}-\bar{x}\right)^{2}
$$

The first term in brackets is the maximum of the partial sums of the first $i$ deviations of $x_{t}$ from the sample mean. Since the sum of all $T$ deviations of the $x_{t}$ s from their mean is zero, this maximum is always nonnegative. The second term is the minimum of the same sequence of partial sums, and hence is always nonpositive. The difference between the two quantities, called the "range" for obvious reasons, is therefore always nonnegative, so that $R_{0} \geq 0$.

ESTIMATING THE FRACTIONAL DIFFERENCING PARAMETER

5.32 A drawback of the $F D-F$ procedure is that, if $d_{1}$ is not known a priori, as it is in the standard Dickey-Fuller case, then a consistent estimate must be provided. A variety of estimators have been suggested, many of which involve quite complex calculations. Perhaps the simplest is suggested by $R / S$ analysis and is

$$
\tilde{d}=\frac{\log R_{0}}{\log T}-0.5
$$

A popular and relatively simple estimator is the log-periodogram regression proposed by Geweke and Porter-Hudak (1983, GPH). From (5.22) the spectral density of $x_{t}$ can be written as

$$
f_{x}(\omega)=\left(4 \sin ^{2}\left(\frac{\omega}{2}\right)\right)^{-d} f_{y}(\omega)
$$

or, on taking logs,

$$
\log f_{x}(\omega)=\log f_{y}(\omega)-d \log 4 \sin ^{2}\left(\frac{\omega}{2}\right)
$$

This leads GPH to propose estimating $d$ as (minus) the slope estimator of the regression

$$
\log I\left(\omega_{j}\right)=a-d \log 4 \sin ^{2}\left(\frac{\omega}{2}\right)
$$

where

$$
I\left(\omega_{j}\right)=2 \hat{\sigma}_{0}^{2}\left(1+2 \sum_{s=1}^{T-1} r_{s} \cos s \omega_{j}\right)
$$

is the periodogram estimate of $f_{x}(\omega)$ at frequencies $\omega_{j}=2 \pi j / T, j=1, \ldots, K$, for a suitable choice of $K$, typically $K=\left[T^{0.5}\right]$. It has been shown that the GPH estimator $\hat{d}$ is consistent for $-0.5<d<1$ and asymptotically normal, so that the estimated standard error attached to $\hat{d}$ can be used for inference. Alternatively, the asymptotic result $\sqrt{K}(\hat{d}-d) \sim N\left(0, \pi^{2} / 24\right)$ may be used.

<h2>Chapter 6 Breaking and Nonlinear Trends</h2>

BREAKING TREND MODELS

6.1 The trend stationary (TS) versus difference stationary (DS) dichotomy and associated testing procedure outlined in $\S \S \mathbf{5 . 9}-\mathbf{5 . 1 0}$ is both simple and straightforward to implement, but is it necessarily realistic? Could the TS alternative of a "global" linear trend be too simplistic in some situations, thus indicating that a more sophisticated trend function might be warranted? Often a more plausible candidate for a trend is a linear function that "breaks" at one or more points in time.

There are several ways in which a trend may break. Assume, for simplicity, that there is a single break at a known point in time $T_{b}^{c}\left(1<T_{b}^{c}<T\right)$, with the superscript " $c$ " denoting the "correct" break date, a distinction that will become important in due course. The simplest breaking trend model is the "level shift" in which the level of $x_{t}$ shifts from $\mu_{0}$ to $\mu_{1}=\mu_{0}+\mu$ at $T_{b}^{c}$. This may be parameterized as

$$
x_{t}=\mu_{0}+\left(\mu_{1}-\mu_{0}\right) \mathrm{DU}_{t}^{c}+\beta_{0} t+\varepsilon_{t}=\mu_{0}+\mu \mathrm{DU}_{t}^{c}+\beta_{0} t+\varepsilon_{t}
$$

where $\mathrm{DU}_{t}^{c}=0$ if $t \leq T_{b}^{c}$ and $\mathrm{DU}_{t}^{c}=1$ if $t>T_{b}^{c}$. This shift variable may be written more concisely as $\mathrm{DU}_{t}^{c}=\mathbf{1}\left(t>T_{b}^{c}\right)$, where $\mathbf{1}(\cdot)$ is the indicator function, so that it takes the value 1 if the argument is true and 0 otherwise. Another possibility is the "changing growth" model in which the slope of the trend changes from $\beta_{0}$ to $\beta_{1}=\beta_{0}+\beta$ at $T_{b}^{c}$ without a change in level. In this case, the trend function is joined at the time of the break and is often referred to as a segmented trend. This model may be parameterized as

$$
x_{t}=\mu_{0}+\beta_{0} t+\left(\beta_{1}-\beta_{0}\right) \mathrm{DT}_{t}^{c}+\varepsilon_{t}=\mu_{0}+\beta_{0} t+\beta \mathrm{DT}_{t}^{c}+\varepsilon_{t}
$$

where $\mathrm{DT}_{t}^{c}=\mathbf{1}\left(t>T_{t}^{c}\right)\left(t-T_{t}^{c}\right)$ models the shift in growth. Both forms of break could, of course, occur simultaneously, so that we would then have the combined model

$$
\begin{aligned}
x_{t} &=\mu_{0}+\left(\mu_{1}-\mu_{0}\right) \mathrm{DU}_{t}^{c}+\beta_{0} t+\left(\beta_{1}-\beta_{0}\right) \mathrm{DT}_{t}^{c}+\varepsilon_{t} \\
&=\mu_{0}+\mu \mathrm{DU}_{t}^{c}+\beta_{0} t+\beta \mathrm{DT}_{t}^{c}+\varepsilon_{t}
\end{aligned}
$$

so that $x_{t}$ undergoes both a shift in level and slope at $T_{b}^{c}$.

BREAKING TRENDS AND UNIT ROOT TESTS

6.3 How can we distinguish between TS breaking trends and breaking DS processes? Clearly unit root tests should be applicable, but what is the influence of breaking trends upon such tests? Perron $(1989,1990$ : see also Perron and Vogelsang, 1993) was the first to consider the impact of breaking trends and shifting levels on unit root tests, showing that standard tests of the type discussed in Chapter 5, Unit Roots, Difference and Trend Stationarity, and Fractional Differencing, are not consistent against TS alternatives when the trend function contains a shift in slope. Here the estimate of the largest autoregressive root is biased toward unity and, in fact, the unit root null becomes impossible to reject, even asymptotically. Although the tests are consistent against a shift in the intercept of the trend function, their power is nevertheless reduced considerably because the limiting value of the estimated autoregressive root is inflated above its true value. 6.4 Perron (1989) consequently extended the Dickey-Fuller unit root testing strategy to ensure consistency against shifting trend functions by developing two asymptotically equivalent procedures. The first uses initial regressions in which $x_{t}$ is detrended according to either model (A), the level shift (6.1); model (B), the segmented trend (6.2); or model (C), the combined model (6.3). Thus, let $\tilde{x}_{t}^{i}, i=A, B, C$, be the residuals from a regression of $x_{t}$ on (1) $i=A$ : a constant, $t$, and $\mathrm{DU}_{t}^{c}$; (2) $i=B$ : a constant, $t$, and DT $T_{t}^{c}$; and (3) $i=C$ : a constant, $t, \mathrm{DU}_{t}^{c}$, and $\mathrm{DT}_{t}^{c}$. For models (A) and (C) a modified ADF regression (cf. (5.5)) is then estimated:

$$
\tilde{x}_{t}^{i}=\tilde{\phi}^{i} \tilde{x}_{t-1}^{i}+\sum_{j=0}^{k} \gamma_{j} \mathrm{D}\left(\mathrm{TB}^{c}\right)_{t-j} \sum_{j=1}^{k} \delta_{j} \nabla \tilde{x}_{t-j}^{i} \quad i=A, C
$$

and a $t$-test of $\tilde{\phi}^{i}=1$ is performed $\left(t^{i}, i=A, C\right)$. The inclusion of the $k+1$ dummy variables $\mathrm{D}\left(\mathrm{TB}^{c}\right)_{t}, \ldots, \mathrm{D}\left(\mathrm{TB}^{c}\right)_{t-k}$ is required to ensure that the limiting distributions of $t^{A}$ and $t^{C}$ are invariant to the correlation structure of the errors (see Perron and Vogelsang, 1993). For model (B) the "unmodified" ADF regression

$$
\tilde{x}_{t}^{B}=\tilde{\phi}^{i} \tilde{x}_{t-1}^{B}+\sum_{j=1}^{k} \delta_{j} \nabla \tilde{x}_{t-j}^{B}+a_{t}
$$

may be estimated to obtain $t^{B}$.

UNIT ROOTS TESTS WHEN THE BREAK DATE IS UNKNOWN

6.10 The procedure set out in $\S \S 6.3-6.5$ is only valid when the break date is known independently of the data, for if a systematic search for a break is carried out then the limiting distributions of the tests are no longer appropriate. Problems also occur if an incorrect break date is selected exogenously, with the tests then suffering size distortions and loss of power.

Consequently, several approaches have been developed that treat the occurrence of the break date as unknown and needing to be estimated: see, for example, Zivot and Andrews (1992), Perron (1997), and Vogelsang and Perron (1998). Thus, suppose now that the correct break date $T_{b}^{c}$ is unknown. Clearly, if this is the case then the models of $\S \$ 6.3-6.5$ are not able to be used until some break date, say $\hat{T}_{b}$, is selected, since none of the dummy variables that these models require can be defined until this selection has been made.

ROBUST TESTS FOR A BREAKING TREND

6.13 Of course, the broken trend will typically be of interest in itself, and so it is natural for the robust trend analysis of $\S \S 5.17-5.22$ to have been extended to cover such specifications, most notably by Harvey, Leybourne, and Taylor (HLT, 2009). If the break date is known to be at $T_{b}^{c}$ with break fraction $\tau_{c}$ then, focusing on the segmented trend model (B), the HLT method is extended by focusing on autocorrelation corrected $t$-tests of $\beta=0$ in (6.2) and (6.5), which we denote as $t_{0}\left(\tau^{c}\right)$ and $t_{1}\left(\tau^{c}\right)$. A weighted average of these two statistics is again considered,

$$
t_{\lambda}=\lambda\left(S_{0}\left(\tau^{c}\right), S_{1}\left(\tau^{c}\right)\right) \times\left|t_{0}\left(\tau^{c}\right)\right|+\left(1-\lambda\left(S_{0}\left(\tau^{c}\right), S_{1}\left(\tau^{c}\right)\right)\right) \times\left|t_{1}\left(\tau^{c}\right)\right|
$$

with the weight function now being defined as

$$
\lambda\left(S_{0}\left(\tau^{c}\right), S_{1}\left(\tau^{c}\right)\right)=\exp \left(-\left(500 S_{0}\left(\tau^{c}\right) S_{1}\left(\tau^{c}\right)\right)^{2}\right)
$$

Here $S_{0}\left(\tau^{c}\right)$ and $S_{1}\left(\tau^{c}\right)$ are KPSS $\eta_{\tau}$ statistics (cf. $\left.\S 5.16\right)$ computed from the residuals of (6.2) and (6.5) respectively. Under $H_{0}: \beta=0, t_{\lambda}$ will be asymptotically standard normal.

CONFIDENCE INTERVALS FOR THE BREAK DATE AND MULTIPLE BREAKS

6.16 When the break date is estimated it is often useful to be able to provide a confidence interval for the unknown $T_{b}^{c}$. Perron and Zhu (2005) show that for the segmented trend model (B) and $I(1)$ errors

$$
\sqrt{T}\left(\hat{\tau}-\tau^{c}\right) \stackrel{d}{\sim} N\left(0,2 \sigma^{2} / 15 \beta^{2}\right)
$$

while for $I(0)$ errors

$$
T^{3 / 2}\left(\tilde{\tau}-\tau^{c}\right) \stackrel{d}{\sim} N\left(0,4 \sigma^{2} /\left(\tau^{c}\left(1-\tau^{c}\right) \beta^{2}\right)\right)
$$

so that, for example, a $95 \%$ confidence interval for $\tau^{c}$ when the errors are $I(1)$ is given by

$$
\hat{\tau} \pm 1.96 \sqrt{\frac{2 \hat{\sigma}^{2}}{15 T \hat{\beta}^{2}}}
$$

The limiting distributions for the break date do not depend on the autocorrelation structure of the errors, only requiring an estimate of the error variance $\sigma^{2}$. When the errors are $I(1)$ the limiting distribution is invariant to the location of the break, whereas for $I(0)$ errors, the limiting distribution depends on the location of the break in such a way that the variance is smaller the closer the break is to the middle of the sample. In both cases the variance decreases as the shift in slope increases.

For model (C) the limiting distributions for the break date are no longer normal but are complicated functions of nuisance parameters and, thus, can only be simulated, so that no simple results are available.

NONLINEAR TRENDS

6.18 A breaking linear trend may be interpreted as a form of nonlinear trend and their use begs the question of why not model nonlinear trends explicitly, particularly when the shift in the trend evolves smoothly over a sequence of observations rather than occurring instantaneously with a sharp break. While many types of deterministic nonlinear trends could be specified, the logistic smooth transition (LSTR) and exponential smooth transition (ESTR) have proved to be popular. The LSTR function may be defined as 

$$
S_{t}(\gamma, m)=(1+\exp (-\gamma(t-m T)))^{-1}
$$

while the ESTR takes the form

$$
S_{t}(\gamma, m)=1-\exp \left(-\gamma(t-m T)^{2}\right)
$$

Analogous to (6.1)-(6.3), three alternative smooth transition trend models may then be specified as

$$
\begin{aligned}
&x_{t}=\mu_{0}+\mu S_{t}(\gamma, m)+\varepsilon_{t} \\
&x_{t}=\mu_{0}+\beta_{0} t+\mu S_{t}(\gamma, m)+\varepsilon_{t} \\
&x_{t}=\mu_{0}+\beta_{0} t+\mu S_{t}(\gamma, m)+\beta t S_{t}(\gamma, m)+\varepsilon_{t}
\end{aligned}
$$

The parameter $m$ determines the timing of the transition midpoint, since for $\gamma>0, S_{-\infty}(\gamma, m)=0, S_{+\infty}(\gamma, m)=1$, and $S_{m T}(\gamma, m)=0.5$. The speed of the transition is determined by the parameter $\gamma$. If $\gamma$ is small then $S_{t}(\gamma, m)$ takes a long time to traverse the interval $(0,1)$, and in the limiting case where $\gamma=0, S_{t}(\gamma, m)=0.5$ for all $t$ and there is, thus, no transition. For large values of $\gamma, S_{t}(\gamma, m)$ traverses the interval $(0,1)$ rapidly, and as $\gamma$ approaches $+\infty$, it changes from zero to one instantaneously at time $m T$, so that a level shift model emerges.

<h2>Chapter 7 An Introduction to Forecasting With Univariate Models</h2>

FORECASTING WITH AUTOREGRESSIVE-INTEGRATED- MOVING AVERAGE (ARIMA) MODELS

7.1 An important feature of the univariate models introduced in previous chapters is their ability to provide forecasts of future values of the observed series. There are two aspects to forecasting: the provision of a forecast for a future value of the series and the provision of a forecast error that can be attached to this point forecast. This forecast error may then be used to construct forecast intervals to provide an indication of the precision these forecasts are likely to possess. The setup is, thus, analogous to the classic statistical problem of estimating an unknown parameter of a model and providing a confidence interval for that parameter.

What is often not realized when forecasting is that the type of model used to construct point and interval forecasts will necessarily determine the properties of these forecasts. Consequently, forecasting from an incorrect or misspecified model may lead to forecasts that are inaccurate and which incorrectly measure the precision that may be attached to them.

<h2>Chapter 8 Unobserved Component Models, Signal Extraction, and Filters</h2>

UNOBSERVED COMPONENT MODEL

8.1 A difference stationary, that is, $I(1)$, time series may always be decomposed into a stochastic nonstationary trend, or signal, component and a stationary noise, or irregular, component:

$$
x_{t}=z_{t}+u_{t}
$$

Such a decomposition can be performed in several ways. For instance, Muth's (1960) classic example assumes that the trend component $z_{t}$ is a random walk

$$
z_{t}=\mu+z_{t-1}+v_{t}
$$

while $u_{t}$ is white noise and independent of $v_{t}$, that is, $u_{t} \sim \mathrm{WN}\left(0, \sigma_{u}^{2}\right)$ and $v_{t} \sim \mathrm{WN}\left(0, \sigma_{v}^{2}\right)$, with $E\left(u_{t} v_{t-i}\right)=0$ for all $i$. Thus, it follows that $\nabla x_{t}$ is the stationary process

$$
\nabla x_{t}=\mu+v_{t}+u_{t}-u_{t-1}
$$

which has an autocorrelation function that cuts off at lag one with coefficient

$$
\rho_{1}=-\frac{\sigma_{u}^{2}}{\sigma_{u}^{2}+2 \sigma_{v}^{2}}
$$

It is clear from (8.3) that $-0.5 \leq \rho_{1} \leq 0$, the exact value depending on the relative sizes of the two variances, so that $\nabla x_{t}$ can be written as the MA(1) process:

$$
\nabla x_{t}=\mu+e_{t}-\theta e_{t-1}
$$

where $e_{t} \sim \operatorname{WN}\left(0, \sigma_{e}^{2}\right)$. On defining $\kappa=\sigma_{v}^{2} / \sigma_{u}^{2}$ to be the signal-to-noise variance ratio, the relationship between the parameters of (8.2) and (8.4) can be shown to be:

$$
\theta=\frac{1}{2}\left((\kappa+2)-\left(\kappa^{2}+4 \kappa\right)^{1 / 2}\right), \quad \kappa=\frac{(1-\theta)^{2}}{\theta}, \quad \kappa \geq 0, \quad|\theta|<1
$$

and

$$
\sigma_{u}^{2}=\theta \sigma_{e}^{2}
$$

Thus, $\kappa=0$ corresponds to $\theta=1$, so that the unit roots in (8.4) "cancel out" and the overdifferenced $x_{t}$ is stationary, while $\kappa=\infty$ corresponds to $\theta=0$, in which case $x_{t}$ is a pure random walk. A test of the stationarity null of $\theta=1$ has been set out in $\S \mathbf{5 . 1 6}$, which can, therefore, also be regarded as a test of the null $\sigma_{v}^{2}=0$, for if this is the case then $z_{t}$ is a deterministic linear trend.

SIGNAL EXTRACTION

8.8 Given a UC model of the form of $(8.1)$ and models for $z_{t}$ and $u_{t}$, it is often useful to provide estimates of these two unobserved components, a procedure that is known as signal extraction. A MMSE estimate of $z_{t}$, is an estimate $\hat{z}_{t}$ which minimizes $E\left(\zeta_{t}^{2}\right)$, where $\zeta_{t}=z_{t}-\hat{z}_{t}$ is the estimation error (cf. \$7.2 ). From, for example, Pierce (1979), given an infinite sample of observations, denoted $\left\{x_{t},-\infty \leq t \leq \infty\right\}$, such an estimator is:

$$
\hat{z}_{t}=\nu_{z}(B) x_{t}=\sum_{j=-\infty}^{\infty} \nu_{z j} x_{t-j}
$$

where the filter $\nu_{z}(B)$ is defined as:

$$
\nu_{z}(B)=\frac{\sigma_{v}^{2} \gamma(B) \gamma\left(B^{-1}\right)}{\sigma_{e}^{2} \theta(B) \theta\left(B^{-1}\right)}
$$

in which case the noise component can be estimated as:

$$
\hat{u}_{t}=x_{t}-\hat{z}_{t}=\left(1-\nu_{z}(B)\right) x_{t}=\nu_{u}(B) x_{t}
$$

For example, for the Muth model of a random walk overlaid with white noise:

$$
\nu_{z}(B)=\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}}(1-\theta B)^{-1}\left(1-\theta B^{-1}\right)^{-1}=\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}} \frac{1}{\left(1-\theta^{2}\right)} \sum_{j=-\infty}^{\infty} \theta^{|j|} B^{j}
$$

so that, using $\sigma_{v}^{2}=(1-\theta)^{2} \sigma_{e}^{2}$, obtained using (8.6), we have:

$$
\hat{z}_{t}=\frac{(1-\theta)^{2}}{1-\theta^{2}} \sum_{j=-\infty}^{\infty} \theta^{|j|} x_{t-j}
$$

Thus, for values of $\theta$ close to unity, $\hat{z}_{t}$ will be given by an extremely long moving average of future and past values of $x$. If $\theta$ is close to zero, however, $\hat{z}_{t}$ will be almost equal to the most recently observed value of $x$. From (8.3), large values of $\theta$ are seen to correspond to small values of the signal-tonoise variance ratio $\kappa=\sigma_{v}^{2} / \sigma_{u}^{2}$. When the noise component dominates, a long moving average of $x$ values will provide the best estimate of the trend, while if the noise component is only small then the trend is essentially given by the current position of $x$.

FILTERS

8.13 The UC model (8.5) is also related to the Hodrick-Prescott trend filter (Hodrick and Prescott, 1997), which is a popular method of detrending economic time series. This filter is derived by minimizing the variation in the noise component $u_{t}=x_{t}-z_{t}$, subject to a condition on the "smoothness" of the trend component $z_{t}$. This smoothness condition penalizes acceleration in the trend, so that the minimization problem becomes that of minimizing the function:

$$
\sum_{t=1}^{T} u_{t}^{2}+\lambda \sum_{t=1}^{T}\left(\left(z_{t+1}-z_{t}\right)-\left(z_{t}-z_{t-1}\right)\right)^{2}
$$

with respect to $z_{t}, t=0,1, \ldots, T+1$, where $\lambda$ is a Lagrangean multiplier that can be interpreted as a smoothness parameter. The higher the value of $\lambda$, the smoother the trend is, so that in the limit, as $\lambda \rightarrow \infty, z_{t}$ becomes a linear trend. The first-order conditions are:

$$
\begin{aligned}
0=&-2\left(x_{t}-z_{t}\right)+2 \lambda\left(\left(z_{t}-z_{t-1}\right)-\left(z_{t-1}-z_{t-2}\right)\right)-4 \lambda\left(\left(z_{t+1}-z_{t}\right)-\left(z_{t}-z_{t-1}\right)\right) \\
&+2 \lambda\left(\left(z_{t+2}-z_{t+1}\right)-\left(z_{t+1}-z_{t}\right)\right)
\end{aligned}
$$

which may be written as:

$$
x_{t}=z_{t}+\lambda(1-B)^{2}\left(z_{t}-2 z_{t+1}+z_{t+2}\right)=\left(1+\lambda(1-B)^{2}\left(1-B^{-1}\right)^{2}\right) z_{t}
$$

so that the Hodrick-Prescott $(\mathrm{H}-\mathrm{P})$ trend estimator is

$$
\hat{z}_{t}(\lambda)=\left(1+\lambda(1-B)^{2}\left(1-B^{-1}\right)^{2}\right)^{-1} x_{t}
$$

The MMSE trend estimator can be written using (8.7) as:

$$
\hat{z}_{t}=\frac{\sigma_{\nu}^{2} \gamma(B) \gamma\left(B^{-1}\right)}{\sigma_{e}^{2} \theta(B) \theta\left(B^{-1}\right)} x_{t}=\frac{\gamma(B) \gamma\left(B^{-1}\right)}{\gamma(B) \gamma\left(B^{-1}\right)+\left(\sigma_{a}^{2} / \sigma_{\nu}^{2}\right) \lambda(B) \lambda\left(B^{-1}\right)} x_{t}
$$

Comparing this with the $\mathrm{H}-\mathrm{P}$ trend estimator (8.18) shows that, for the latter to be optimal in the MMSE sense, we must set

$$
\gamma(B)=(1-B)^{-1}, \quad \lambda(B)=1, \quad \delta=\frac{\sigma_{a}^{2}}{\sigma_{\nu}^{2}}
$$

In other words, the underlying UC model must have the trend component $\nabla^{2} z_{t}=\nu_{t}$ and $u_{t}$ must be white noise. 8.14 Setting $\lambda=100$ is often suggested when extracting a trend from an annual series. Theoretical and simulation analyses have, however, suggested using a much higher value when using annual data (see Harvey and Trimbur, 2008; Flaig, 2015, for example): other choices are discussed by Ravn and Uhlig (2002) and Maravall and del Rio (2007). For example, Ravn and Uhlig suggest that, if there are $s$ periods per year (e.g., 12 if the data is observed monthly), then the smoothing parameter should be set at $\lambda=1600(s / 4)^{m}$, where $m$ is set at either 2 or 4 (if the former this yields $\lambda=100$ for annual data; if the latter then $\lambda=6.25$ ).

However, if, as is likely in practice, the object of using an H-P filter has the purely descriptive aim of extracting a smooth trend component with a smoothly evolving growth rate, then some experimentation with different, and possibly high, values of $\lambda$ is probably warranted.

<h2>Chapter 9 Seasonality and Exponential Smoothing</h2>

MODELING STOCHASTIC SEASONALITY

9.3 It would, however, be imprudent to rule out the possibility of an evolving seasonal pattern: in other words, the presence of stochastic seasonality. As in the modeling of stochastic trends, ARIMA processes have been found to do an excellent job in modeling stochastic seasonality, albeit in an extended form to that developed in previous chapters.

MIXED SEASONAL MODELS

9.12 The deterministic and stochastic seasonal models, (9.1) and (9.5), may be combined to form, on setting $d=D=1$ for both simplicity and because these are the settings that are typically found,

$$
x_{t}=\sum_{i=1}^{m} \alpha_{i} s_{i, t}+\frac{\theta_{q}(B) \Theta_{Q}\left(B^{m}\right)}{\phi_{p}(B) \Phi_{P}\left(B^{m}\right) \nabla \nabla_{m}} a_{t}
$$

"Pure" stochastic seasonality simply requires that no seasonal dummies are significant in (9.8), i.e., that $\alpha_{1}=\alpha_{2}=\cdots=\alpha_{m}=0$. Establishing whether there is "pure" deterministic seasonality is somewhat more complicated, for it requires both that the seasonal moving average polynomial $\Theta_{Q}\left(B^{m}\right)$ contains a seasonal unit root, i.e., that it can be factorized as $\Theta_{\varrho}\left(B^{m}\right)=\nabla_{m} \Theta_{Q-1}\left(B^{m}\right)$, so that the seasonal difference "cancels out," and also that $\Theta_{Q-1}\left(B^{m}\right)=\Phi_{P}\left(B^{m}\right)$, so that the seasonal polynomials in (9.8) also cancel out. Formally testing these hypotheses is quite complicated and will not be discussed here. ${ }^{5}$ 

SEASONAL ADJUSTMENT

9.13 In $\S 2.16$ we introduced a decomposition of an observed time series into trend, seasonal, and irregular (or noise) components, focusing attention on estimating the seasonal component and then eliminating it to provide a seasonally adjusted series. Extending the notation introduced in (8.1), this implicit UC decomposition can be written as

$$
x_{t}=z_{t}+s_{t}+u_{t}
$$

where the additional seasonal component $s_{t}$ is assumed to be independent of both $z_{t}$ and $u_{t}$. On obtaining an estimate of the seasonal component, $\hat{s}_{t}$, the seasonally adjusted series can then be defined as $x_{t}^{a}=x_{t}-\hat{s}_{t}$.

EXPONENTIAL SMOOTHING

$9.15$ Returning to the two-component UC model, (8.1), where $x_{t}=z_{t}+u_{t}$, then a simple model for the signal or "level" $z_{t}$ is to assume that its current value is an exponentially weighted moving average of current and past observations of $x_{t}$ :

$$
\begin{aligned}
z_{t} &=\alpha x_{t}+\alpha(1-\alpha) x_{t-1}+\alpha(1-\alpha)^{2} x_{t-2}+\cdots=\alpha \sum_{j=0}^{\infty}(1-\alpha)^{j} x_{t-j} \\
&=\alpha\left(1+(1-\alpha) B+(1-\alpha)^{2} B^{2}+\cdots+(1-\alpha)^{j} B^{j}+\cdots\right) x_{t}
\end{aligned}
$$

Since, ${ }^{7}$

$$
1+(1-\alpha) B+(1-\alpha)^{2} B^{2}+\cdots+(1-\alpha)^{j} B^{j}+\cdots=(1-(1-\alpha) B)^{-1}
$$

Eq. (9.10) can be written as:

$$
(1-(1-\alpha) B) z_{t}=\alpha x_{t}
$$

or,

$$
z_{t}=\alpha x_{t}+(1-\alpha) z_{t-1}
$$

This shows that the current level, $z_{t}$, is a weighted average of the current observation, $x_{t}$, and the previous level, $z_{t-1}$, the weight being given by the "smoothing constant" $\alpha$. Alternatively, (9.11) can be expressed in "error correction" form as:

$$
z_{t}=z_{t-1}+\alpha\left(x_{t}-z_{t-1}\right)=z_{t-1}+\alpha e_{t}
$$

so that the current level is updated from the previous level by a proportion of the current error $e_{t}=x_{t}-z_{t-1}$, the proportion again being given by the smoothing constant $\alpha$.

Smoothing

In Example 4.3, an $\operatorname{ARIMA}(0,1,3)$ process without drift was fitted to monthly global temperatures, and in Example $7.2$ this model was used to provide forecasts out to 2020 . As $\hat{\theta}_{2}$ and $\hat{\theta}_{3}$, although significant, are both small when compared to $\hat{\theta}_{1}$, an ARIMA( $\left.0,1,1\right)$ process should provide a decent fit to the series, and indeed it does, with $\hat{\theta}=0.55$ and a root mean square error (RMSE) of $0.1255$ [compared with $0.1236$ for $\operatorname{ARIMA}(0,1,3)$. From the equivalence of simple exponential smoothing and the $\operatorname{ARIMA}(0,1,1)$, we would expect the former model to produce a similar fit and forecasts for a smoothing parameter of $\alpha=0.45$. Fitting the series by simple exponential smoothing and estimating $\alpha$ does indeed lead to this value for the smoothing parameter, an RMSE of $0.1257$, and forecasts given by $f_{T, h}=z_{T}=0.581$. These should be compared to the $\operatorname{ARIMA}(0,1,3)$ forecasts obtained in Example 7.2, which, for $h>2$, are equal to $0.621$.

Acknowledging the possibility of a linear trend in global temperatures would require the use of either double exponential smoothing or Holt-Winters. The former estimates the single smoothing parameter to be $\gamma=0.196$, accompanied by an RMSE of $0.1319$. Interestingly, double exponential smoothing gives $z_{T}=0.569$ and $\tau_{T}=-0.014$, so that, using (9.14), forecasts will contain a negatively sloped, albeit small, linear trend. Holt-Winters estimates the smoothing parameters as $\alpha=0.45$ and $\beta=0$, which implies that the trend component is a constant, so that $\tau_{t}=\tau_{t-1}=\cdots=\tau, \quad$ a value that is estimated by $x_{2}-x_{1}=0.0005$. The Holt-Winters forecasts thus include a small positive linear trend which increases the forecasts from $0.582$ to $0.599$ by the end of the forecast period, December 2020. In either case, there is an absence of a significant positive drift in the forecasts, consistent with our earlier findings. Given that the RMSE of Holt-Winters was $0.1256$, this implies that simple exponential smoothing is the most appropriate of these three techniques for forecasting monthly global temperatures.

9.20 Seasonality can easily be accommodated within the Holt-Winters framework. Based on (9.9), the additive Holt-Winters level updating equation (9.12) becomes

$$
\begin{aligned}
z_{t}=& \alpha\left(x_{t}-s_{t-m}\right)+(1-\alpha)\left(z_{t-1}+\tau_{t-1}\right)=z_{t-1}+\tau_{t-1} \\
&+\alpha\left(x_{t}-s_{t-m}-z_{t-1}-\tau_{t-1}\right)=z_{t-1}+\tau_{t-1}+\alpha e_{t}
\end{aligned}
$$

The trend updating equation remains as (9.13) and there is an additional seasonal updating equation

$$
s_{t}=\delta\left(x_{t}-z_{t}\right)+(1-\delta) s_{t-m}=s_{t-m}+\delta(1-\beta) e_{t}
$$

Forecasts are then given by

$$
f_{T, h}=z_{T}+\tau_{T}+s_{T+h-m}
$$

These updating equations can be shown (Newbold, 1988) to be equivalent to the ARIMA model:

$$
\nabla \nabla_{m} x_{t}=\theta_{m+1}(B) a_{t}
$$

where

$$
\begin{aligned}
\theta_{1} &=1-\alpha-\alpha \beta \\
\theta_{2} &=\cdots=\theta_{m-1}=-\alpha \beta \\
\theta_{m} &=1-\alpha \beta-(1-\alpha) \delta \\
\theta_{m+1} &=-(1-\alpha)(1-\delta)
\end{aligned}
$$

If $\beta=0$, so that the trend is constant, then if $\theta_{1} \theta_{m}+\theta_{m+1}=0$ as well, or equivalently $2-2 \delta+\alpha \delta=0$, (9.16) reduces to the $\operatorname{ARIMA}(0,1,1)(0,1,1)_{m}$ airline model. Indeed, the airline model will also result if both $\alpha \beta$ and $\alpha \delta$ are negligibly small.

<h2>Chapter 10 Volatility and Generalized Autoregressive Conditional Heteroskedastic Processes</h2>

VOLATILITY

10.1 Following initial research on portfolio theory during the 1950 s, volatility became an extremely important concept in finance, appearing regularly in models of, for example, asset pricing and risk management. Although there are various definitions of volatility, in the context of a time series it is generally taken to be a period in the evolution of the series that is associated with high variability or, equivalently, high variance. This was prompted by the observation that many time series, not just financial returns, appear to be characterized by alternating periods of relative tranquility in which variability is low and relative volatility where variability is considerably higher.

AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTIC PROCESSES

10.5 Up until this point we have said nothing about how the conditional variances $\sigma_{t}^{2}$ might be generated. We now consider the case where they are a function of past values of $x_{t}$ :

$$
\sigma_{t}^{2}=f\left(x_{t-1}, x_{t-2}, \ldots\right)
$$

A simple example is:

$$
\sigma_{t}^{2}=f\left(x_{t-1}\right)=\alpha_{0}+\alpha_{1}\left(x_{t-1}-\mu\right)^{2}
$$

where $\alpha_{0}$ and $\alpha_{1}$ are both positive to ensure that $\sigma_{t}^{2}>0$. With $U_{t} \sim \operatorname{NID}(0,1)$ and independent of $\sigma_{t}, x_{t}=\mu+\sigma_{t} U_{t}$ is then conditionally normal,

$$
x_{t} \mid x_{t-1}, x_{t-2}, \ldots \sim \mathrm{N}\left(\mu, \sigma_{t}^{2}\right)
$$

so that

$$
V\left(x_{t} \mid x_{t-1}\right)=\alpha_{0}+\alpha_{1}\left(x_{t-1}-\mu\right)^{2}
$$

If $0<\alpha_{1}<1$ then the unconditional variance is $V\left(x_{t}\right)=\alpha_{0} /\left(1-\alpha_{1}\right)$ and $x_{t}$ is weakly stationary. It may be shown that the fourth moment of $x_{t}$ is finite if $3 \alpha_{1}^{2}<1$ and, if so, the kurtosis of $x_{t}$ is given by $3\left(1-\alpha_{1}^{2}\right) /\left(1-3 \alpha_{1}^{2}\right)$. Since this must exceed 3, the unconditional distribution of $x_{t}$ is fatter tailed than the normal. If this moment condition is not satisfied, then the variance of $x_{t}$ will be infinite and $x_{t}$ will not be weakly stationary.

TESTING FOR THE PRESENCE OF ARCH ERRORS

10.12 Let us suppose that an ARMA model for $x_{t}$ has been estimated, from which the residuals $e_{t}$ have been obtained. The presence of ARCH may lead to serious model misspecification if it is ignored. As with all forms of heteroskedasticity (i.e., nonconstant error variance), analysis assuming its absence will result in inappropriate parameter standard errors, these typically being too small. For example, ignoring ARCH will lead to the identification of ARMA models that tend to be overparameterized, as parameters that should be set to zero will show up as significant. 10.13 Methods for testing whether ARCH is present or not are, therefore, essential, particularly as estimation incorporating ARCH innovations requires complicated iterative techniques. Eq. (10.3) has shown that if $\varepsilon_{t}$ is GARCH $(p, q)$ then $\varepsilon_{t}^{2}$ is $\operatorname{ARMA}(m, p)$, where $m=\max (p, q)$, and standard ARMA theory follows through in this case. This implies that the squared residuals $e_{t}^{2}$ from the estimation of a pure ARMA process can then be used to identify $m$ and $p$, and therefore $q$, in a similar fashion to the way the residuals themselves are used in conventional ARMA modeling. For example, the sample autocorrelations of $e_{t}^{2}$ have asymptotic variance $T^{-1}$ and portmanteau statistics calculated from them are asymptotically $\chi^{2}$ if the $\varepsilon_{t}^{2}$ are independent.

FORECASTING FROM AN ARMA-GARCH MODEL

10.20 Suppose we have the $\operatorname{ARMA}(P, Q)$-GARCH $(p, q)$ model of $\S$ 10.11:

$$
\begin{gathered}
x_{t}=\Phi_{1} x_{t-1}+\cdots+\Phi_{P} x_{t-P}+\Theta_{0}+\varepsilon_{t}-\Theta_{1} \varepsilon_{t-1}-\cdots-\Theta_{Q} \varepsilon_{t-Q} \\
\sigma_{t}^{2}=\alpha_{0}+\alpha_{1} \varepsilon_{t-1}^{2}+\cdots+\alpha_{p} \varepsilon_{t-p}^{2}+\beta_{1} \sigma_{t-1}^{2}+\cdots+\beta_{q} \sigma_{t-q}^{2}
\end{gathered}
$$

Forecasts of $x_{T+h}$ can be obtained from the "mean equation" (10.7) in the manner outlined in $\S \S$ 7.1-7.4. When calculating forecast error variances, however, it can no longer be assumed that the error variance itself is constant. Thus, (7.4) must be amended to:

$$
V\left(e_{t, h}\right)=\sigma_{T+h}^{2}+\psi_{1}^{2} \sigma_{T+h-1}^{2}+\cdots+\psi_{h-1}^{2} \sigma_{T+1}^{2}
$$

with the $\sigma_{T+h}^{2}$ being obtained recursively from (10.8). 

<h2>Chapter 11 Nonlinear Stochastic Processes</h2>

MARTINGALES, RANDOM WALKS, AND NONLINEARITY

11.1 In $\S \mathbf{1 0 . 2}$ a distinction was drawn between serial uncorrelatedness and independence. Although this distinction lies at the heart of GARCH modeling, it is also of more general importance, manifesting itself in the concept of a martingale; a stochastic process that is a mathematical model of "fair play." A martingale may be defined as a stochastic process $x_{t}$ having the following properties: ${ }^{2}$

1. $E\left(\left|x_{t}\right|\right)<\infty$ for each $t$;

2. $E\left(x_{t} \mid x_{s}, x_{s-1}, \ldots\right)=x_{s}$.

Written as

$$
E\left(x_{t}-x_{s} \mid x_{s}, x_{s-1}, \ldots\right)=0, \quad s<t,
$$

the martingale property implies that the MMSE forecast of a future increment of a martingale is zero. This property can be generalized to situations where:

$$
E\left(x_{t}-x_{s} \mid x_{s}, x_{s-1}, \ldots\right) \geq 0, \quad s<t,
$$

in which we have a sub-martingale, and to the case where this inequality is reversed, giving us a super-martingale.

NONLINEAR STOCHASTIC MODELS

11.7 As discussed in $\S 3$ 3.6, Wold's decomposition theorem allows us to represent every weakly stationary, purely nondeterministic, stochastic process as a linear combination of a sequence of uncorrelated random variables, as in (3.2). A stochastic process can then be considered nonlinear if it does not satisfy the assumptions underlying the decomposition, for example, if the representation is:

$$
x_{t}-\mu=f\left(a_{t}, a_{t-1}, a_{t-2}, \ldots\right)
$$

where $f(\cdot)$ is some arbitrary nonlinear function. However, the "curse of dimensionality" means that this representation is of little practical use. Consequently, as an approximation to $f(\cdot)$, consider a Taylor expansion of (11.2) around zero:

$$
x_{t}-\mu=f\left(0, a_{t-1}, a_{t-2}\right)+a_{t} f^{\prime}\left(0, a_{t-1}, a_{t-2}\right)+0.5 a_{t}^{2} f^{\prime \prime}\left(0, a_{t-1}, a_{t-2}\right)+\cdots
$$

where $f^{\prime}$ and $f^{\prime \prime}$ are the first and second derivatives of $f$ with respect to $a_{t}$. By dropping higher-order terms, we can express $x_{t}$ in terms of its conditional moments. For example, by keeping only the first two terms, $x_{t}$ can be expressed as a function of the conditional mean and variance, respectively. Simple forms of nonlinearity can also be obtained by assuming some loworder polynomial function for $f(\cdot)$ : for example, the first-order nonlinear moving average (see Robinson, 1977).

$$
x_{t}=a_{t}+\psi_{1} a_{t-1}^{2}
$$

Polynomial functions of lagged $x_{t}$ can also be used (Jones, 1978), while another simple way of introducing nonlinearity is to allow $x_{t}$ to respond in a different manner to innovations depending on their sign. For example, Wecker (1981) introduced the asymmetric moving average process, whose first-order form is:

$$
x_{t}=a_{t}+\theta a_{t-1}+\psi \mathbf{1}\left(a_{t-1}>0\right) a_{t-1}
$$

This model was extended to include both moving average and autoregressive components by Brännäs and De Gooijer (1994).

BILINEAR MODELS

11.9 An important class of nonlinear model is the bilinear, which takes the general form

$$
\phi(B)\left(x_{t}-\mu\right)=\theta(B) \varepsilon_{t}+\sum_{i=1}^{R} \sum_{j=1}^{S} \gamma_{i j} x_{t-i} \varepsilon_{t-j}
$$

Here $\varepsilon_{t} \sim S W N\left(0, \sigma_{\varepsilon}^{2}\right)$, where this notation is used to denote that the innovations $\varepsilon_{t}$ are strict white noise. The second term on the right hand side of (11.3) is a bilinear form in $\varepsilon_{t-j}$ and $x_{t-i}$, and this accounts for the nonlinear character of the model, for if all the $\gamma_{i j}$ are zero, (11.3) clearly reduces to the familiar ARMA model. The bilinear model can be thought of as a higherorder Taylor approximation to the unknown nonlinear function $f(\cdot)$ than that provided by the Wold decomposition.

THRESHOLD AND SMOOTH TRANSITION AUTOREGRESSIONS

11.18 A popular class of nonlinear model is the self-exciting threshold autoregressive (SETAR) process, which allows for asymmetry by defining a set of piecewise autoregressive models whose switch points, or "thresholds," are generally unknown (see Tong and Lim, 1980; Tong, 1990; Teräsvirta, 2006):

$$
x_{t}=\sum_{j=1}^{r}\left(\phi_{j, 1} x_{t-1}+\cdots+\phi_{j, p} x_{t-p}+a_{j, t}\right) \mathbf{1}\left(c_{j-1}<x_{t-d} \leq c_{j}\right)
$$

Here $d$ is the (integer-valued) delay parameter and $c_{1}<c_{2}<\cdots<c_{r-1}$ are the thresholds: the model is often denoted $\operatorname{SETAR}(r: p, d) .{ }^{3}$ It is assumed that $a_{j, t} \sim W N\left(0, \sigma_{j}^{2}\right), j=1, \ldots, r$, so that the error variance is allowed to alter across the $r$ "regimes." A popular version of (11.7) is the two-regime SETAR $(2: p, d)$ model:

$$
\begin{aligned}
x_{t}=&\left(\phi_{1,1} x_{t-1}+\cdots+\phi_{1, p} x_{t-p}+a_{1, t}\right) \mathbf{1}\left(x_{t-d} \leq c_{1}\right) \\
&+\left(\phi_{2,1} x_{t-1}+\cdots+\phi_{2, p} x_{t-p}+a_{2, t}\right)\left(1-\mathbf{1}\left(x_{t-d} \leq c_{1}\right)\right)
\end{aligned}
$$

An important feature of the SETAR model is its ability to generate "limit cycles": if (11.7) is extrapolated assuming that the error terms equal zero, then the extrapolated series displays oscillations of a given length that do not die out.

As previously stated, asymmetry may be captured by the regimes: for example, if $x_{t-d}$ measures the phase of an economic business cycle, a tworegime SETAR could describe processes whose dynamic properties differ across expansions and recessions. If the transition variable $x_{t-d}$ is replaced by its difference $\nabla x_{t-d}$, then any asymmetry lies in the growth rate of the series so that, for example, increases in growth rates may be rapid but the return to a lower level of growth may be slow.

If the transition variable $x_{t-d}$ is replaced by $t$ then the model becomes an autoregression with $r-1$ breaks at times $c_{1}, \ldots, c_{r-1}$.

MARKOV-SWITCHING MODELS

11.21 Yet another way of introducing asymmetry is to consider "regime switching" models. Hamilton $(1989,1990)$, Engle and Hamilton (1990), and Lam (1990) all propose variants of a switching-regime Markov model, which can be regarded as a nonlinear extension of an ARMA process that can accommodate complicated dynamics, such as asymmetry and conditional heteroskedasticity. The setup is that of the UC model of $\S \mathbf{8} .1$, i.e., Eq. (8.1), where $z_{t}$ now evolves as a two-state Markov process:

$$
z_{t}=\alpha_{0}+\alpha_{1} S_{t}
$$

where

$$
\begin{gathered}
P\left(S_{t}=1 \mid S_{t-1}=1\right)=p \\
P\left(S_{t}=0 \mid S_{t-1}=1\right)=1-p \\
P\left(S_{t}=1 \mid S_{t-1}=0\right)=1-q \\
P\left(S_{t}=0 \mid S_{t-1}=0\right)=q
\end{gathered}
$$

The noise component $u_{t}$ is assumed to follow an AR $(r)$ process $\phi(B) u_{t}=\varepsilon_{t}$, where the innovation sequence $\varepsilon_{t}$ is strict white noise but $\phi(B)$ may contain a unit root, so that, unlike the conventional UC specification, $u_{t}$ can be nonstationary. In fact, a special case of the conventional UC model results when $p=1-q$. The random walk component then has an innovation restricted to be a two-point random variable, taking the values 0 and 1 with probabilities $q$ and $1-q$ respectively, rather than a zero-mean random variable drawn from a continuous distribution, such as the normal.

NEURAL NETWORKS

11.24 Neural networks (NNs) refer to a broad class of nonparametric models which have gained a good deal of popularity in recent years across a wide range of disciplines, including computer science, psychology, biology, linguistics, and pattern recognition (for a textbook treatment, see, for example, Haykin, 1999). These models originate from research in the cognitive sciences on emulating the structure and behavior of the human brain.

One of the most common types of NN is the multi-layered perceptron (MLP), which can be used for nonparametric regression and classification. These models are organized in three basic layers: the input layer of independent variables, the output layer of dependent variables, and one or more hidden layers in-between. An activation function regulates the dependencies between the elements of each layer. A univariate autoregressive MLP model with a single hidden layer can be represented as:

$$
x_{t}=\sum_{i=1}^{p} \phi_{i} x_{t-i}+\sum_{j=1}^{q} \beta_{j} G\left(\sum_{i=1}^{p} \varphi_{i} x_{t-i}\right)+\varepsilon_{t}
$$

$G(\cdot)$ is the activation function and is a bounded nonlinear function that operates in an analogous manner to that of the transition functions used in STAR models. Several activation functions are employed in practice, with the most common being the hyperbolic tangent and the logistic. The second term in (11.13) refers to the hidden layer in the MLP. Obviously, (11.13) collapses to a standard $\operatorname{AR}(p)$ model when the activation function is linear. The residual term $\varepsilon_{t}$ is usually assumed to be a white noise random variable.

NONLINEAR DYNAMICS AND CHAOS

11.28 So far, all the processes introduced in this chapter have the common aim of modeling stochastic nonlinearities in time series. This would seem the natural approach to take when dealing with stochastic time series processes, but a literature has also developed that considers the question of whether such series could have been generated, at least in part, by nonlinear deterministic laws of motion.

11.29 Research in the general area of nonlinear dynamics is concerned with the behavior of deterministic and stochastic nonlinear systems. Both applied and theoretical research has flourished over the past four decades across a variety of disciplines and an extensive overview of the research on nonlinear dynamics, albeit with a bias toward the natural sciences, is given by Hilborn (1997). The meaning of the term "nonlinear dynamics" seems to vary considerably across scientific disciplines and eras. For example, a popular interpretation, since the early $1980 \mathrm{~s}$, associates nonlinear dynamics with deterministic nonlinear systems and a specific dynamic behavior called chaos, although this term has itself been given several different interpretations. 11.30 This diversity of meanings is mainly a consequence of there being no formal and complete mathematical definition of a chaotic system (see, for example, Berliner, 1992). Broadly speaking, chaos is the mathematical condition whereby a simple (low-dimensional), nonlinear, dynamical system produces complex (infinite-dimensional or random-like) behavior. Even though these systems are deterministic, they are completely unpredictable in the long-run, due to "sensitive dependence on initial conditions," also known as Lyapunov instability. Chaotic systems also invariably have "fractal" or "self-similar" pictorial representations.

<h2>Chapter 12 Transfer Functions and Autoregressive Distributed Lag Modeling</h2>

12.1 The models that have been developed so far in this book have all been univariate, so that the current value of a time series depends, linearly or otherwise, only on past values of itself and, perhaps, a deterministic function of time. While univariate models are important in themselves, they also play a key role in providing a "baseline" to which multivariate models may be compared. We shall analyze several multivariate models over the next chapters, but our development begins with the simplest. This is the single-input transfer function-noise model, in which an endogenous, or output, variable $y_{t}$ is related to a single input, or exogenous, variable $x_{t}$ through the dynamic model ${ }^{1}$

$$
y_{t}=v(B) x_{t}+n_{t}
$$

where the lag polynomial $v(B)=v_{0}+v_{1} B+v_{2} B^{2}+\cdots$ allows $x$ to influence $y$ via a distributed lag: $v(B)$ is often referred to as the transfer function and the coefficients $v_{i}$ as the impulse response weights.

AUTOREGRESSIVE DISTRIBUTED LAG MODELS

12.8 Nevertheless, it would clearly be useful if an automatic model selection procedure could be developed. This has not been done for the multiple input model (12.4), but if a restricted form of it is specified then such a procedure becomes feasible. This restricted form is known as the autoregressive distributed lag, or ARDL, model and is obtained by placing the following restrictions on (12.4):

$$
\delta_{1}(B)=\cdots=\delta_{M}(B)=\phi(B) \quad \theta(B)=1
$$

so that the model is, on defining $\beta_{j}(B)=\omega_{j}(B) B^{b_{j}}$ and including an intercept,

$$
\phi(B) y_{t}=\beta_{0}+\sum_{j=1}^{M} \beta_{j}(B) x_{j, t}+a_{t}
$$

This is known as the $\operatorname{ARDL}\left(p, s_{1}, \ldots, s_{M}\right)$ model and restricts all the autoregressive lag polynomials to be the same and excludes a moving average noise component, although this exclusion is not essential. These restrictions reduce the noise component to white noise through constraining the dynamics and enables (12.5) to be estimated by OLS, so that on selecting a maximum lag order of, say, $m$, goodness-of-fit statistics, such as information criteria, can be used to select the appropriate specification.

<h2>Chapter 13 Vector Autoregressions and Granger Causality</h2>

MULTIVARIATE DYNAMIC REGRESSION MODELS

13.1 In a natural extension to the ARDL model of the previous chapter, suppose that there are now two endogenous variables, $y_{1, t}$ and $y_{2, t}$, that may both be related to an exogenous variable $x_{t}$ and its lags as well as to lags of each other. In the simplest case, such a model would be:

$$
\begin{aligned}
&y_{1, t}=c_{1}+a_{11} y_{1, t-1}+a_{12} y_{2, t-1}+b_{10} x_{t}+b_{11} x_{t-1}+u_{1, t} \\
&y_{2, t}=c_{2}+a_{21} y_{1, t-1}+a_{22} y_{2, t-1}+b_{20} x_{t}+b_{21} x_{t-1}+u_{2, t}
\end{aligned}
$$

The "system" contained in Eq. (13.1) is known as a multivariate dynamic regression, a model treated in some detail in Spanos (1986, Chapter 24). Note that the "contemporaneous" variables, $y_{1, t}$ and $y_{2, t}$, are not included as regressors in the equations for $y_{2, t}$ and $y_{1, t}$, respectively, as this would lead to simultaneity and an identification problem, in the sense that the two equations making up (13.1) would then be statistically indistinguishable, there being the same variables in both. Of course, $y_{1, t}$ and $y_{2, t}$ may well be contemporaneously correlated, and any such correlation can be modeled by allowing the covariance between the innovations to be nonzero, so that $E\left(u_{1, t} u_{2, t}\right)=\sigma_{12}$ say, the variances of the two innovations then being $E\left(u_{1}^{2}\right)=\sigma_{1}^{2}$ and $E\left(u_{2}^{2}\right)=\sigma_{2}^{2}$.

VECTOR AUTOREGRESSIONS

13.4 Suppose the model (13.2) does not contain any exogenous variables, so that all the $\mathbf{B}_{i}$ matrices are zero, and that there are $p$ lags of the endogenous variables in every equation:

$$
\mathbf{y}_{t}=\mathbf{c}+\sum_{i=1}^{p} \mathbf{A}_{i} \mathbf{y}_{t-i}+\mathbf{u}_{t}
$$

Because (13.3) is now simply a $p$ th order autoregression in the vector $\mathbf{y}_{t}$ it is known as a vector autoregression $(\operatorname{VAR}(p))$ of dimension $n$ and, again, can be estimated by multivariate least squares. ${ }^{3}$ It is assumed that all the series contained in $\mathbf{y}_{t}$ are stationary, which requires that the roots of the characteristic equation associated with (13.3),

$$
\mathbf{A}(B)=\mathbf{I}_{n}-\mathbf{A}_{1} B-\cdots-\mathbf{A}_{p} B^{p}=\mathbf{0}
$$

have moduli that are less than unity (bearing in mind that some of the $n p$ roots may appear as complex conjugates).

VARs have become extremely popular for modeling multivariate systems of time series because the absence of $\mathbf{x}_{t}$ terms precludes having to make any endogenous-exogenous classification of the variables, for such distinctions are often considered to be highly contentious.

GRANGER CAUSALITY

13.5 In the VAR (13.3) the presence of nonzero off-diagonal elements in the $\mathbf{A}_{i}$ matrices, $a_{r s, i} \neq 0, r \neq s$, implies that there are dynamic relationships between the variables, otherwise the model would collapse to a set of $n$ univariate AR processes. The presence of such dynamic relationships is known as Granger (-Sims) causality. ${ }^{4}$ The variable $y_{s}$ does not Granger-cause the variable $y_{r}$ if $a_{r s, i}=0$ for all $i=1,2, \ldots, p$. If, on the other hand, there is at least one $a_{r s, i} \neq 0$ then $y_{s}$ is said to Granger-cause $y_{r}$ because if that is the case then past values of $y_{s}$ are useful in forecasting the current value of $y_{r}$ : Granger causality is, thus, a criterion of "forecastability." If $y_{r}$ also Grangercauses $y_{s}$, the pair of variables are said to exhibit feedback.

DETERMINING THE LAG ORDER OF A VECTOR AUTOREGRESSION

13.8 To enable the VAR to become operational the lag order $p$, which will typically be unknown, needs to be determined empirically. A traditional way of selecting the lag order is to use a sequential testing procedure. Consider the model (13.3) with error covariance matrix $\boldsymbol{\Omega}_{p}=E\left(\mathbf{u}_{t} \mathbf{u}_{t}^{\prime}\right)$, where a $p$ subscript is included to emphasize that the matrix is related to a $\operatorname{VAR}(p)$. An estimate of this matrix is given by:

$$
\hat{\boldsymbol{\Omega}}_{p}=(T-p)^{-1} \hat{\mathbf{U}}_{p} \hat{\mathbf{U}}_{p}^{\prime}
$$

where $\hat{\mathbf{U}}_{p}=\left(\hat{\mathbf{u}}_{p, 1}^{\prime}, \ldots, \hat{\mathbf{u}}_{p, n}^{\prime}\right)^{\prime}$ is the matrix of residuals obtained by OLS estimation of the $\operatorname{VAR}(p), \hat{\mathbf{u}}_{p, r}=\left(\hat{u}_{r, p+1}, \ldots, \hat{u}_{r, T}\right)^{\prime}$ being the residual vector from the $r$ th equation (noting that with a sample of size $T, p$ observations will be lost through lagging). A likelihood ratio (LR) statistic for testing the order $p$ against the order $m, m<p$, is

$$
L R(p, m)=(T-n p) \log \left(\frac{\left|\hat{\boldsymbol{\Omega}}_{m}\right|}{\left|\hat{\boldsymbol{\Omega}}_{p}\right|}\right) \sim \chi_{n^{2}(p-m)}^{2}
$$

Thus, if $L R(p, m)$ exceeds the $\alpha$ critical value of the $\chi^{2}$ distribution with $n^{2}(p-m)$ degrees of freedom, then the hypothesis that the VAR order is $m$ is rejected at the $\alpha$ level of significance in favor of the higher order $p$. The statistic uses the scaling factor $T-n p$ rather than $T-p$ to account for possible small sample bias.

The statistic (13.4) may then be used sequentially beginning with a maximum value of $p, p_{\max }$ say, testing first $p_{\max }$ against $p_{\max }-1$ using $L R\left(p_{\max }, p_{\max }-1\right)$ and, if this statistic is not significant, then testing $p_{\max }-1$ against $p_{\max }-2$ using $L R\left(p_{\max }-1, p_{\max }-2\right)$, continuing until a significant test is obtained.

Alternatively, some type of information criterion can be minimized. These are essentially multivariate extensions of those initially introduced in §3.35: for example, the multivariate AIC and BIC criteria are defined as:

$$
\begin{aligned}
&\operatorname{MAIC}(p)=\log \left|\hat{\boldsymbol{\Omega}}_{p}\right|+\left(2+n^{2} p\right) T^{-1} \\
&\operatorname{MBIC}(p)=\log \left|\hat{\Omega}_{p}\right|+n^{2} p T^{-1} \ln T \quad p=0,1, \ldots, p_{\max }
\end{aligned}
$$

VARIANCE DECOMPOSITIONS AND INNOVATION ACCOUNTING

13.10 While the estimated coefficients of a $\operatorname{VAR}(1)$ are relatively easy to interpret, this quickly becomes problematic for higher order VARs because not only do the number of coefficients increase rapidly (each additional lag introduces a further $n^{2}$ coefficients), but many of these coefficients will be imprecisely estimated and highly intercorrelated, so becoming statistically insignificant. This can be seen in the estimated VAR(2) of Example 13.1, where only $\hat{a}_{22,2}$ in $\hat{\mathbf{A}}_{2}$ is significant.

STRUCTURAL VECTOR AUTOREGRESSIONS

13.15 The "noninvariance property" of VARs has generated much detailed analysis and criticism of the variance decomposition methodology, mainly focusing on the inability of VARs to be regarded as "structural" in the traditional econometric sense, so that shocks cannot be uniquely identified with a specific variable unless prior identifying assumptions are made, without which the computed impulse response functions and variance decompositions would be invalid. The triangular "recursive" structure of $\mathbf{S}$ has been criticized for being atheoretical, and has led to the development of other sets of identifying restrictions that are based more explicitly on theoretical considerations using the structural VAR (SVAR) approach: see Cooley and LeRoy (1985); Blanchard (1989); and Blanchard and Quah (1989).

<h2>Chapter 14 Error Correction, Spurious Regressions, and Cointegration</h2>

THE ERROR CORRECTION FORM OF AN AUTOREGRESSIVE DISTRIBUTED LAG MODEL

14.1 The simplest case of the ARDL (autoregressive distributed lag) model introduced in $\S \mathbf{1 2 . 7}$ is the $\operatorname{ARDL}(1,1)$ :

$$
y_{t}=\beta_{0}+\phi y_{t-1}+\beta_{1,0} x_{t}+\beta_{1,1} x_{t-1}+a_{t}
$$

Suppose now that we recast this ARDL by writing it as

$$
\nabla y_{t}=\beta_{0}-(1-\phi) y_{t-1}+\left(\beta_{1,0}+\beta_{1,1}\right) x_{t-1}+\beta_{1,0} \nabla x_{t}+a_{t}
$$

or

$$
\nabla y_{t}=\beta_{1,0} \nabla x_{t}-(1-\phi)\left(y_{t-1}-\frac{\beta_{0}}{1-\phi}-\frac{\beta_{1,0}+\beta_{1,1}}{1-\phi} x_{t-1}\right)+a_{t}
$$

i.e., as

$$
\nabla y_{t}=\beta_{1,0} \nabla x_{t}-(1-\phi)\left(y_{t-1}-\theta_{0}-\theta_{1} x_{t-1}\right)+a_{t}
$$

This representation of the ARDL expresses the current change in the endogenous variable, $\nabla y_{t}$, as a linear function of the current change in the exogenous variable $\nabla x_{t}$ and a proportion $1-\phi$ of the previous discrepancy (or error) from the long-run "equilibrium" relationship $y=\theta_{0}+\theta_{1} x$. The representation (14.2) is known as the error-correction model or ECM. If the parameters of the equilibrium relationship are unknown, then they may be estimated either by using nonlinear least squares on (14.2) or by expressing the ECM as

$$
\nabla y_{t}=\beta_{0}+\beta_{1,0} \nabla x_{t}+\gamma\left(y_{t-1}-x_{t-1}\right)+\delta x_{t-1}+a_{t}
$$

which may be estimated directly by OLS and where a comparison of (14.3) with (14.2) shows that

$$
\theta_{0}=-\frac{\beta_{0}}{\gamma} \quad \theta_{1}=\frac{\gamma-\delta}{\gamma}
$$

The ECM was introduced originally by Sargan (1964) and further analyzed by, for example, Davidson et al. (1978). It may readily be extended to the general $\operatorname{ARDL}\left(p, s_{1}, \ldots, s_{M}\right)$ model. Denoting the error correction as

$$
e c_{t}=y_{t}-\theta_{0}-\sum_{j=1}^{M} \theta_{j} x_{j, t}
$$

then (14.2) generalizes to

$$
\begin{aligned}
\nabla y_{t}=& \beta_{0}-\phi(1) e c_{t-1}+\phi^{*}(B) \nabla y_{t-1}+\sum_{j=1}^{M} \tilde{\beta}_{j}(B) \nabla x_{j, t-1} \\
&+\sum_{j=1}^{M} \beta_{j}(B) \nabla x_{j, t}+a_{t}
\end{aligned}
$$

where

$$
\phi^{*}(B)=\sum_{i=1}^{p} \phi_{i} B^{i}=\phi(B)-1
$$

SPURIOUS REGRESSIONS

14.2 As in Chapter 12, Transfer Functions and Autoregressive Distributed Lag Modeling, it has been implicitly assumed that all the variables entering the ARDL/ECM are stationary, so that any nonstationary series have been appropriately differenced beforehand. What would happen if nonstationary variables were not prior differenced but were entered as levels? That there is a theoretical issue is clearly apparent. The standard proof of the consistency of OLS when there are stochastic regressors, as there are here, relies on the assumption that the probability limit of $T^{-1} \boldsymbol{X}^{\prime} \boldsymbol{X}$, where $\boldsymbol{X}$ is a matrix containing the data on the explanatory variables, tends to a fixed matrix; i.e., the matrix of expectations of sums of squares and cross-products of the data tends to a matrix of constants (see, for example, Mills, 2013a, $\S \S 6.3-6.4$ ). In other words, as the sample size $T$ increases, the sample moments of the data settle down to their population values. For there to be fixed population moments to which these sample moments converge, the data must be stationary. If it was not, then, as in the case of integrated series, the data may display a tendency to increase in magnitude over time, so that there are no fixed values in the matrix of expectations of sums of squares and crossproducts of these data.

<h2>Chapter 16 Compositional and Count Time Series</h2>

CONSTRAINED TIME SERIES

16.1 In previous chapters we considered time series that generally have no restrictions placed upon them apart from when they have a natural lower bound, this often being zero. There are, however, some series, or groups of series, that are bound by further constraints. When modeling such series, a "good" model should be unable to predict values which violate the known constraints, that is, the model should be "forecast coherent." Two examples of these types of series are considered in this chapter: (1) compositional time series in which a group of series are defined as shares of a whole, so that they must be positive fractions that sum to unity; and (2) "count" time series that can only take on positive, and typically low, integer values.

MODELING COMPOSITIONAL DATA

16.2 A compositional data set is one in which the $T$ observations on $D=d+1$ variables, written in matrix form as

$$
\boldsymbol{X}=\left[\begin{array}{cccc}
x_{1,1} & x_{1,2} & \cdots & x_{1, D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2, D} \\
\vdots & \vdots & & \vdots \\
x_{T, 1} & x_{T, 2} & \cdots & x_{T, D}
\end{array}\right]=\left[\begin{array}{llll}
\boldsymbol{x}_{1} & \boldsymbol{x}_{2} & \cdots & \boldsymbol{x}_{D}
\end{array}\right]
$$

where $\boldsymbol{x}_{i}=\left(x_{1, i}, x_{2, i}, \ldots, x_{T, i}\right)^{\prime}, i=1,2, \ldots, D$, are such that $x_{t, i}>0$ and $x_{t, 1}+x_{t, 2}+\cdots+x_{t, D}=1, t=1,2, \ldots, T$, that is, $\boldsymbol{x}_{i}>\mathbf{0}$ and

$$
\boldsymbol{x}_{1}+\boldsymbol{x}_{2}+\cdots+\boldsymbol{x}_{D}=\boldsymbol{\iota}
$$

where $\iota=\left[\begin{array}{llll}1 & 1 & \cdots & 1\end{array}\right]^{\prime}$ is a $T \times 1$ unit vector. The sub-matrix

$$
\boldsymbol{X}^{(d)}=\left[\begin{array}{llll}
\boldsymbol{x}_{1} & \boldsymbol{x}_{2} & \cdots & \boldsymbol{x}_{d}
\end{array}\right]
$$

then lies in the d-dimensional simplex $\mathcal{S}^{d}$ embedded in D-dimensional real space with

$$
\boldsymbol{x}_{D}=\iota-\sum_{i=1}^{d} \boldsymbol{x}_{i}
$$

being the vector of 'fill-up' values and $X=\left[\begin{array}{ll}\boldsymbol{X}^{(d)} & \boldsymbol{x}_{D}\end{array}\right]$.

TIME SERIES MODELS FOR COUNTS: THE IN-AR(1) BENCHMARK MODEL

16.8 Time series of small numbers of counts arise in various fields and typically consist of integer values, usually including zero, with a sample mean perhaps no higher than 10 , making it inappropriate to treat the data as if it were continuous. We will focus here on the so-called integer-valued ARMA (IN-ARMA) models that provide an interesting class of discrete valued processes that are able to specify not only the dependence structure of the series of counts, but also enable a choice to be made between a wide class of (discrete) marginal distributions.

OTHER INTEGER-VALUED ARMA PROCESSES

16.12 The IN-MA(1) process is defined as

$$
x_{t}=w_{t}+b \circ w_{t-1}
$$

where $0 \leq b<1$ and the thinning operation is defined analogously to (16.7) as

$$
b \circ w_{t-1}=\sum_{i=1}^{w_{t-1}} y_{i, t-1}
$$

The autocorrelation function (ACF) of $x_{t}$ is now

$$
\rho_{k}=\left\{\begin{array}{ccc}
\frac{b \sigma_{w}^{2}}{b(1-b) \mu_{w}+\left(1+b^{2}\right) \sigma_{w}^{2}} & \text { for } & k=1 \\
0 & \text { for } & k>1
\end{array}\right.
$$

which is analogous to the linear MA(1) process (cf. \$3.12). It is straightforward to show that $0 \leq \rho_{1} \leq 0.5$ and that, if again $w_{t} \sim P o(\lambda)$, $x_{t} \sim P o(\lambda(1+b))$ and the resulting process is Po-IN-MA(1).

FORECASTING COUNTS

16.19 The approach to forecasting taken in Chapter 7, An Introduction to Forecasting with Univariate Models, is based on the conditional expectation, that is,

$$
f_{T, h}=E\left(x_{T+h} \mid x_{T}, x_{T-1}, \ldots, x_{1}\right)
$$

and is known to yield MMSE forecasts (cf. §7.2). The conditional expectation of the IN-AR(1) model is given in $\S 16.10$, so that

$$
\begin{gathered}
f_{T, 1}=a x_{T}+\mu_{w} \\
f_{T, 2}=a f_{T, 1}+\mu_{w}=a^{2} x_{T}+(1+a) \mu_{w}
\end{gathered}
$$

and

$$
f_{T, h}=a^{h} x_{T}+\left(1+a+a^{2}+\cdots+a^{h-1}\right) \mu_{w}
$$

Since $0 \leq a<1$ the forecasts converge as $h \rightarrow \infty$ to the unconditional mean $E\left(x_{t}\right)=\mu_{w} /(1-a)$. Despite this optimality property, forecasting based on (16.9) is beset by the problem that forecasts so obtained will be real, rather than integer, valued except in very rare cases. Of course, integervalued forecasts may be readily obtained by, for example, the simple expedient of rounding to the nearest integer, but this rather crude solution prevents proper forecast intervals being obtained and it is not immediately obvious how forecast values should be incorporated when $h>1$. Jung and Tremayne (2006) suggest a simple, albeit ad hoc, way of acknowledging the arbitrary nature of the rounding procedure. This is to apportion probabilities to the integers on either side of the incoherent real value in proportion to the distances from either end of that unit interval.

<h2>Chapter 17 State Space Models</h2>

FORMULATING STATE SPACE MODELS

17.1 Many time series models can be cast in state space form (SSF), and this enables a unified framework of analysis to be presented within which, for example, the differences and similarities of the alternative models may be assessed.

The state space model for a univariate time series $x_{t}$ consists of both a measurement equation (alternatively known as the signal or observation equation) and a transition equation (alternatively state equation: see, e.g., Harvey, 1989, Chapters 3 and 4; Hamilton, 1994, Chapter 13; or Durbin and Koopman, 2012, for full textbook treatments). Although there are various specifications of the SSF, a popular version has the measurement equation taking the form:

$$
x_{t}=z_{t}^{\prime} \boldsymbol{\alpha}_{t}+d_{t}+\varepsilon_{t} \quad t=1,2, \ldots, T
$$

Here $z_{t}$ is an $m \times 1$ vector, $d_{t}$ is a scalar, and $\varepsilon_{t}$ is a serially uncorrelated error with $E\left(\varepsilon_{t}\right)=0$ and $V\left(\varepsilon_{t}\right)=h_{t}$. In general, the elements of the $m \times 1$ state vector $\alpha_{t}$ are unobservable, but are assumed to be generated by the transition equation

$$
\boldsymbol{\alpha}_{t}=\boldsymbol{T}_{t} \boldsymbol{\alpha}_{t-1}+\boldsymbol{c}_{t}+\boldsymbol{R}_{t} \boldsymbol{\eta}_{t}
$$

in which $\boldsymbol{T}_{t}$ and $\boldsymbol{R}_{t}$ are $m \times m$ and $m \times g$ matrices, respectively, $\boldsymbol{c}_{t}$ is an $m \times 1$ vector and $\eta_{t}$ is a $g \times 1$ vector of serially uncorrelated errors with $E\left(\boldsymbol{\eta}_{t}\right)=\mathbf{0}$ and $V\left(\boldsymbol{\eta}_{t}\right)=\boldsymbol{Q}_{t}$, a $g \times g$ covariance matrix. The specification of the state space system is completed by two further assumptions:

1. The initial state $\boldsymbol{\alpha}_{0}$ has mean vector $E\left(\boldsymbol{\alpha}_{0}\right)=\boldsymbol{a}_{0}$ and covariance matrix $V\left(\boldsymbol{\alpha}_{0}\right)=\boldsymbol{P}_{0} ;$ and

2. The errors $\varepsilon_{t}$ and $\eta_{t}$ are uncorrelated with each other in all time periods and uncorrelated with the initial state, that is,

$$
E\left(\varepsilon_{t} \boldsymbol{\eta}_{s}^{\prime}\right)=\mathbf{0} \text { for all } s, t=1, \ldots, T
$$

and

$$
E\left(\varepsilon_{t} \boldsymbol{\alpha}_{0}^{\prime}\right)=\mathbf{0} \quad E\left(\boldsymbol{\eta}_{t} \boldsymbol{\alpha}_{0}^{\prime}\right)=\mathbf{0} \quad \text { for all } t=1, \ldots, T
$$

THE KALMAN FILTER

17.8 Once a model has been put into state space form, several important algorithms may be applied. Central to these is the Kalman (-Bucy) filter. The Kalman filter is a recursive procedure for computing the optimal estimate of the state vector at time $t$, based on the information available at that time, which consists of all the observations up to and including $x_{t} \cdot{ }^{1}$ The system matrices, together with the initial values $\boldsymbol{a}_{0}$ and $\boldsymbol{P}_{0}$, are assumed to be known for all $t$ and so do not need to be included explicitly in the information set.

ESTIMATION AND THE PREDICTION ERROR DECOMPOSITION

17.12 The system matrices may depend on a set of unknown parameters, as with the ARMA process whose SSF was given in $\S \mathbf{1 7 . 3}$. The parameters may be denoted by an $n \times 1$ vector $\psi$ and will be referred to as the hyperparameters of the SSF. These hyperparameters may be estimated by ML, the classical theory of which is based on the $T$ observations $x_{1}, \ldots, x_{T}$ being i.i.d. This allows the joint density function of the observations to be written as:

$$
\mathcal{L}(x: \psi)=\prod_{t=1}^{T} p\left(x_{t}\right)
$$

where $\boldsymbol{x}^{\prime}=\left(x_{1}, \ldots, x_{T}\right)$ and $p\left(x_{t}\right)$ is the probability density function of $x_{t}$. Once the observations have become available, $\mathcal{L}(x: \psi)$ is reinterpreted as a likelihood function and the ML estimator is found by maximizing this function with respect to $\psi$.

MULTIVARIATE STATE SPACE MODELS

17.19 This development of state space models has been based on modeling a univariate time series $x_{t}$. The analysis may readily be extended to modeling the $N \times 1$ vector $\boldsymbol{X}_{t}$ of observed series by generalizing the measurement equation (17.1) to

$$
X_{t}=Z_{t} \alpha_{t}+d_{t}+\varepsilon_{t}
$$

where $\boldsymbol{Z}_{t}$ is an $N \times m$ matrix, $\boldsymbol{d}_{t}$ is an $N \times 1$ vector, and $\varepsilon_{t}$ is an $N \times 1$ vector with $E\left(\varepsilon_{t}\right)=\mathbf{0}$ and $V\left(\varepsilon_{t}\right)=\boldsymbol{H}_{t}$, an $N \times N$ covariance matrix. The analysis then carries through with the necessary changes. 





